{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb, time\n",
    "import numpy as np\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined signals shape: (7, 3825000)\n",
      "Combined labels shape: (510,)\n",
      "Sampling frequency: 250\n",
      "Preprocessing signals...\n",
      "Preprocessed signals shape: (7, 3825000)\n",
      "Preprocessing completed.\n",
      "Segmentation started...\n",
      "Segmented signals shape: (510, 52500)\n",
      "Number of labels: 510\n",
      "Feature extraction started...\n",
      "Extracting features...\n",
      "Ensuring consistent feature dimensions...\n",
      "Number of feature dictionaries: 510\n",
      "Feature extraction completed.\n",
      "Normalizing features...\n",
      "Number of normalized feature dictionaries: 510\n",
      "Feature normalization completed.\n",
      "Converting features to matrix...\n",
      "Feature matrix shape: (510, 151)\n",
      "Feature conversion completed.\n",
      "Filtering features based on mutual information...\n",
      "Top 20 Features (Sorted by Importance):\n",
      "D2_range: 0.1348\n",
      "D3_energy: 0.1176\n",
      "D4_percentile_75: 0.1100\n",
      "A5_percentile_25: 0.0996\n",
      "D1_range: 0.0982\n",
      "D5_percentile_25: 0.0944\n",
      "D3_hjorth_activity: 0.0916\n",
      "D1_energy: 0.0911\n",
      "D1_hjorth_activity: 0.0905\n",
      "D1_std: 0.0899\n",
      "D2_hjorth_activity: 0.0717\n",
      "D2_std: 0.0709\n",
      "D2_energy: 0.0706\n",
      "D3_range: 0.0687\n",
      "D1_shannon_entropy: 0.0673\n",
      "D3_percentile_75: 0.0671\n",
      "D1_percentile_25: 0.0657\n",
      "D2_ar_coeff_3: 0.0653\n",
      "D3_std: 0.0642\n",
      "D3_hjorth_complexity: 0.0615\n",
      "\n",
      "Selected Features (MI > 0.01): ['D2_range', 'D3_energy', 'D4_percentile_75', 'A5_percentile_25', 'D1_range', 'D5_percentile_25', 'D3_hjorth_activity', 'D1_energy', 'D1_hjorth_activity', 'D1_std', 'D2_hjorth_activity', 'D2_std', 'D2_energy', 'D3_range', 'D1_shannon_entropy', 'D3_percentile_75', 'D1_percentile_25', 'D2_ar_coeff_3', 'D3_std', 'D3_hjorth_complexity']\n",
      "Feature filtering completed.\n",
      "Performing mRMR feature selection...\n",
      "Mutual Information Scores for All Features:\n",
      "D2_range: 0.0060\n",
      "D3_energy: 0.0899\n",
      "D4_percentile_75: 0.0911\n",
      "A5_percentile_25: 0.0484\n",
      "D1_range: 0.0982\n",
      "D5_percentile_25: 0.0558\n",
      "D3_hjorth_activity: 0.0673\n",
      "D1_energy: 0.0216\n",
      "D1_hjorth_activity: 0.0223\n",
      "D1_std: 0.0000\n",
      "D2_hjorth_activity: 0.0000\n",
      "D2_std: 0.0000\n",
      "D2_energy: 0.0000\n",
      "D3_range: 0.0905\n",
      "D1_shannon_entropy: 0.0075\n",
      "D3_percentile_75: 0.0037\n",
      "D1_percentile_25: 0.0000\n",
      "D2_ar_coeff_3: 0.0000\n",
      "D3_std: 0.0124\n",
      "D3_hjorth_complexity: 0.0344\n",
      "A5_percentile_75: 0.0502\n",
      "D3_ar_coeff_2: 0.0513\n",
      "D1_percentage_energy: 0.0657\n",
      "D5_percentile_75: 0.0155\n",
      "D4_ar_coeff_3: 0.0147\n",
      "D1_ar_coeff_4: 0.0003\n",
      "D1_ar_coeff_3: 0.0709\n",
      "D4_std: 0.0706\n",
      "D4_hjorth_activity: 0.0000\n",
      "D1_entropy: 0.1348\n",
      "D4_energy: 0.0317\n",
      "D3_percentage_energy: 0.0007\n",
      "D3_percentile_25: 0.0024\n",
      "D5_energy: 0.0027\n",
      "D5_hjorth_activity: 0.0000\n",
      "D5_std: 0.0000\n",
      "A5_std: 0.0082\n",
      "D5_range: 0.0000\n",
      "A5_range: 0.0717\n",
      "A5_hjorth_activity: 0.0338\n",
      "D4_percentile_25: 0.0115\n",
      "D4_shannon_entropy: 0.0157\n",
      "A5_ar_coeff_4: 0.0000\n",
      "D1_ar_coeff_2: 0.0000\n",
      "A5_energy: 0.0218\n",
      "D2_hjorth_mobility: 0.0653\n",
      "A5_percentage_energy: 0.0120\n",
      "D2_percentage_energy: 0.0093\n",
      "D4_percentile_50: 0.0160\n",
      "A5_shannon_entropy: 0.0000\n",
      "D4_skewness: 0.0217\n",
      "D3_hjorth_mobility: 0.0642\n",
      "D1_renyi_entropy: 0.1176\n",
      "D2_ar_coeff_2: 0.0186\n",
      "D3_mean: 0.0687\n",
      "D1_tsallis_entropy: 0.0471\n",
      "D2_bandwidth: 0.0000\n",
      "D5_hjorth_complexity: 0.0036\n",
      "D3_entropy: 0.0029\n",
      "D4_ar_coeff_2: 0.0000\n",
      "D5_percentage_energy: 0.0000\n",
      "D3_percentile_50: 0.0000\n",
      "D3_center_frequency: 0.0138\n",
      "D1_center_frequency: 0.0916\n",
      "D2_spectral_value_at_fc: 0.0249\n",
      "D2_percentile_50: 0.0615\n",
      "D2_skewness: 0.0000\n",
      "D3_bandwidth: 0.0000\n",
      "D1_percentile_50: 0.0000\n",
      "D4_bandwidth: 0.0567\n",
      "D1_percentile_75: 0.0050\n",
      "D5_ar_coeff_4: 0.0000\n",
      "D5_shannon_entropy: 0.0462\n",
      "D5_hjorth_mobility: 0.0174\n",
      "D1_ar_coeff_1: 0.0671\n",
      "D1_bandwidth: 0.0020\n",
      "D2_ar_coeff_4: 0.0490\n",
      "D2_hjorth_complexity: 0.0481\n",
      "D5_ar_coeff_2: 0.0000\n",
      "\n",
      "Top 10 Selected Features: ['D3_energy', 'D4_percentile_75', 'D1_range', 'D3_range', 'D1_ar_coeff_3', 'D4_std', 'D1_entropy', 'A5_range', 'D1_renyi_entropy', 'D1_center_frequency']\n",
      "mRMR feature selection completed.\n",
      "Top Selected Features: ['D3_energy', 'D4_percentile_75', 'D1_range', 'D3_range', 'D1_ar_coeff_3', 'D4_std', 'D1_entropy', 'A5_range', 'D1_renyi_entropy', 'D1_center_frequency']\n",
      "Training and evaluating SVM...\n",
      "Training SVM...\n",
      "SVM training completed in 0.01 seconds.\n",
      "Evaluating SVM...\n",
      "Confusion Matrix:\n",
      "[[77  0]\n",
      " [16  9]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Wake       0.83      1.00      0.91        77\n",
      "       Sleep       1.00      0.36      0.53        25\n",
      "\n",
      "    accuracy                           0.84       102\n",
      "   macro avg       0.91      0.68      0.72       102\n",
      "weighted avg       0.87      0.84      0.81       102\n",
      "\n",
      "\n",
      "Accuracy: 0.8431372549019608\n",
      "SVM training and evaluation completed.\n",
      "Pipeline completed.\n"
     ]
    }
   ],
   "source": [
    "patient_files = [\n",
    "            ('C:/Users/anany/Downloads/slp32', 'C:/Users/anany/Downloads/slp32.st'),\n",
    "            # ('C:/Users/anany/Downloads/slp37', 'C:/Users/anany/Downloads/slp37.st'),\n",
    "            # ('C:/Users/anany/Downloads/slp41', 'C:/Users/anany/Downloads/slp41.st'),\n",
    "            # ('C:/Users/anany/Downloads/slp45', 'C:/Users/anany/Downloads/slp45.st'),\n",
    "            # ('C:/Users/anany/Downloads/slp48', 'C:/Users/anany/Downloads/slp48.st')\n",
    "        ]\n",
    "\n",
    "combined_signals = []\n",
    "combined_labels = []\n",
    "\n",
    "for dat_file, st_file in patient_files:\n",
    "    record = wfdb.rdrecord(dat_file)  \n",
    "    annotations = wfdb.rdann(dat_file, 'st')  \n",
    "\n",
    "    signals = record.p_signal  \n",
    "    fs = record.fs  \n",
    "    signal_names = record.sig_name  \n",
    "\n",
    "    aux_notes = annotations.aux_note  # Sleep stage and apnea annotations\n",
    "    annotation_times = annotations.sample  # Annotation times (in samples)\n",
    "\n",
    "    stage_mapping = {\n",
    "        'W': 0,  # Wake\n",
    "        '1': 1,  # NREM1\n",
    "        '2': 1,  # NREM2\n",
    "        '3': 1,  # NREM3\n",
    "        '4': 1,  # NREM3 (combined with stage 3)\n",
    "        'R': 1   # REM\n",
    "    }\n",
    "\n",
    "    sleep_stages = []\n",
    "    for aux in aux_notes:\n",
    "        stage = aux.strip()  \n",
    "        if stage in stage_mapping:  # Check if the stage is in the mapping\n",
    "            sleep_stages.append(stage_mapping[stage])\n",
    "\n",
    "    total_samples = len(sleep_stages) * fs * 30  \n",
    "    signals = [signal[:total_samples] for signal in signals.T] \n",
    "    signals = np.array(signals)  \n",
    "\n",
    "    combined_signals.append(signals)\n",
    "    combined_labels.extend(sleep_stages)\n",
    "\n",
    "combined_signals = np.concatenate(combined_signals, axis=1)  \n",
    "combined_labels = np.array(combined_labels)  \n",
    "print(\"Combined signals shape:\", combined_signals.shape)\n",
    "print(\"Combined labels shape:\", combined_labels.shape)\n",
    "print(\"Sampling frequency:\", fs)\n",
    "\n",
    "main_pipeline(combined_signals, combined_labels, fs, \"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined signals shape: (7, 0)\n",
      "Combined labels shape: (0,)\n",
      "Sampling frequency: 250\n",
      "Preprocessing signals...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The length of the input vector x must be greater than padlen, which is 9.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCombined labels shape:\u001b[39m\u001b[33m\"\u001b[39m, combined_labels.shape)\n\u001b[32m     49\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSampling frequency:\u001b[39m\u001b[33m\"\u001b[39m, fs)\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[43mmain_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_signals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombined_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbinary\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anany\\Desktop\\OSA\\sleep_stage_paper_implementation\\utils.py:322\u001b[39m, in \u001b[36mmain_pipeline\u001b[39m\u001b[34m(raw_signals, labels, fs, type)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain_pipeline\u001b[39m(raw_signals, labels, fs, \u001b[38;5;28mtype\u001b[39m):\n\u001b[32m    320\u001b[39m     \u001b[38;5;66;03m# Step 1: Preprocess the signals\u001b[39;00m\n\u001b[32m    321\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPreprocessing signals...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     preprocessed_signals = \u001b[43mpreprocess_signals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_signals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     preprocessed_signals = np.array(preprocessed_signals) \n\u001b[32m    324\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPreprocessed signals shape:\u001b[39m\u001b[33m\"\u001b[39m, preprocessed_signals.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anany\\Desktop\\OSA\\sleep_stage_paper_implementation\\utils.py:30\u001b[39m, in \u001b[36mpreprocess_signals\u001b[39m\u001b[34m(raw_signals, fs)\u001b[39m\n\u001b[32m     27\u001b[39m preprocessed_signals = []\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m signal \u001b[38;5;129;01min\u001b[39;00m raw_signals:\n\u001b[32m     29\u001b[39m     \u001b[38;5;66;03m# Apply notch filter\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     filtered_signal = \u001b[43mnotch_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# Apply bandpass filter\u001b[39;00m\n\u001b[32m     32\u001b[39m     filtered_signal = bandpass_filter(filtered_signal, fs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anany\\Desktop\\OSA\\sleep_stage_paper_implementation\\utils.py:19\u001b[39m, in \u001b[36mnotch_filter\u001b[39m\u001b[34m(data, fs, freq, quality)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnotch_filter\u001b[39m(data, fs, freq=\u001b[32m50\u001b[39m, quality=\u001b[32m30\u001b[39m):\n\u001b[32m     18\u001b[39m     b, a = signal.iirnotch(freq, quality, fs)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msignal\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfiltfilt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anany\\Desktop\\OSA\\env\\Lib\\site-packages\\scipy\\signal\\_signaltools.py:4525\u001b[39m, in \u001b[36mfiltfilt\u001b[39m\u001b[34m(b, a, x, axis, padtype, padlen, method, irlen)\u001b[39m\n\u001b[32m   4522\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m y\n\u001b[32m   4524\u001b[39m \u001b[38;5;66;03m# method == \"pad\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4525\u001b[39m edge, ext = \u001b[43m_validate_pad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadlen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4526\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mntaps\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4528\u001b[39m \u001b[38;5;66;03m# Get the steady state of the filter's step response.\u001b[39;00m\n\u001b[32m   4529\u001b[39m zi = lfilter_zi(b, a)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anany\\Desktop\\OSA\\env\\Lib\\site-packages\\scipy\\signal\\_signaltools.py:4574\u001b[39m, in \u001b[36m_validate_pad\u001b[39m\u001b[34m(padtype, padlen, x, axis, ntaps)\u001b[39m\n\u001b[32m   4572\u001b[39m \u001b[38;5;66;03m# x's 'axis' dimension must be bigger than edge.\u001b[39;00m\n\u001b[32m   4573\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.shape[axis] <= edge:\n\u001b[32m-> \u001b[39m\u001b[32m4574\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mThe length of the input vector x must be greater \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4575\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[33mthan padlen, which is \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m % edge)\n\u001b[32m   4577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m padtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m edge > \u001b[32m0\u001b[39m:\n\u001b[32m   4578\u001b[39m     \u001b[38;5;66;03m# Make an extension of length `edge` at each\u001b[39;00m\n\u001b[32m   4579\u001b[39m     \u001b[38;5;66;03m# end of the input array.\u001b[39;00m\n\u001b[32m   4580\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m padtype == \u001b[33m'\u001b[39m\u001b[33meven\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[31mValueError\u001b[39m: The length of the input vector x must be greater than padlen, which is 9."
     ]
    }
   ],
   "source": [
    "patient_files = [\n",
    "            # ('C:/Users/anany/Downloads/slp32', 'C:/Users/anany/Downloads/slp32.st'),\n",
    "            # ('C:/Users/anany/Downloads/slp37', 'C:/Users/anany/Downloads/slp37.st'),\n",
    "            ('C:/Users/anany/Downloads/slp41', 'C:/Users/anany/Downloads/slp41.st'),\n",
    "            # ('C:/Users/anany/Downloads/slp45', 'C:/Users/anany/Downloads/slp45.st'),\n",
    "            # ('C:/Users/anany/Downloads/slp48', 'C:/Users/anany/Downloads/slp48.st')\n",
    "        ]\n",
    "\n",
    "combined_signals = []\n",
    "combined_labels = []\n",
    "\n",
    "for dat_file, st_file in patient_files:\n",
    "    record = wfdb.rdrecord(dat_file)  \n",
    "    annotations = wfdb.rdann(dat_file, 'st')  \n",
    "\n",
    "    signals = record.p_signal  \n",
    "    fs = record.fs  \n",
    "    signal_names = record.sig_name  \n",
    "\n",
    "    aux_notes = annotations.aux_note  # Sleep stage and apnea annotations\n",
    "    annotation_times = annotations.sample  # Annotation times (in samples)\n",
    "\n",
    "    stage_mapping = {\n",
    "        'W': 0,  # Wake\n",
    "        '1': 1,  # NREM1\n",
    "        '2': 1,  # NREM2\n",
    "        '3': 1,  # NREM3\n",
    "        '4': 1,  # NREM3 (combined with stage 3)\n",
    "        'R': 1   # REM\n",
    "    }\n",
    "\n",
    "    sleep_stages = []\n",
    "    for aux in aux_notes:\n",
    "        stage = aux.strip()  \n",
    "        if stage in stage_mapping:  # Check if the stage is in the mapping\n",
    "            sleep_stages.append(stage_mapping[stage])\n",
    "\n",
    "    total_samples = len(sleep_stages) * fs * 30  \n",
    "    signals = [signal[:total_samples] for signal in signals.T] \n",
    "    signals = np.array(signals)  \n",
    "\n",
    "    combined_signals.append(signals)\n",
    "    combined_labels.extend(sleep_stages)\n",
    "\n",
    "combined_signals = np.concatenate(combined_signals, axis=1)  \n",
    "combined_labels = np.array(combined_labels)  \n",
    "print(\"Combined signals shape:\", combined_signals.shape)\n",
    "print(\"Combined labels shape:\", combined_labels.shape)\n",
    "print(\"Sampling frequency:\", fs)\n",
    "\n",
    "main_pipeline(combined_signals, combined_labels, fs, \"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined signals shape: (7, 0)\n",
      "Combined labels shape: (0,)\n",
      "Sampling frequency: 250\n",
      "Preprocessing signals...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The length of the input vector x must be greater than padlen, which is 9.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCombined labels shape:\u001b[39m\u001b[33m\"\u001b[39m, combined_labels.shape)\n\u001b[32m     49\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSampling frequency:\u001b[39m\u001b[33m\"\u001b[39m, fs)\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[43mmain_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_signals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombined_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbinary\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anany\\Desktop\\OSA\\sleep_stage_paper_implementation\\utils.py:322\u001b[39m, in \u001b[36mmain_pipeline\u001b[39m\u001b[34m(raw_signals, labels, fs, type)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain_pipeline\u001b[39m(raw_signals, labels, fs, \u001b[38;5;28mtype\u001b[39m):\n\u001b[32m    320\u001b[39m     \u001b[38;5;66;03m# Step 1: Preprocess the signals\u001b[39;00m\n\u001b[32m    321\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPreprocessing signals...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     preprocessed_signals = \u001b[43mpreprocess_signals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_signals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     preprocessed_signals = np.array(preprocessed_signals) \n\u001b[32m    324\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPreprocessed signals shape:\u001b[39m\u001b[33m\"\u001b[39m, preprocessed_signals.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anany\\Desktop\\OSA\\sleep_stage_paper_implementation\\utils.py:30\u001b[39m, in \u001b[36mpreprocess_signals\u001b[39m\u001b[34m(raw_signals, fs)\u001b[39m\n\u001b[32m     27\u001b[39m preprocessed_signals = []\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m signal \u001b[38;5;129;01min\u001b[39;00m raw_signals:\n\u001b[32m     29\u001b[39m     \u001b[38;5;66;03m# Apply notch filter\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     filtered_signal = \u001b[43mnotch_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# Apply bandpass filter\u001b[39;00m\n\u001b[32m     32\u001b[39m     filtered_signal = bandpass_filter(filtered_signal, fs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anany\\Desktop\\OSA\\sleep_stage_paper_implementation\\utils.py:19\u001b[39m, in \u001b[36mnotch_filter\u001b[39m\u001b[34m(data, fs, freq, quality)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnotch_filter\u001b[39m(data, fs, freq=\u001b[32m50\u001b[39m, quality=\u001b[32m30\u001b[39m):\n\u001b[32m     18\u001b[39m     b, a = signal.iirnotch(freq, quality, fs)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msignal\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfiltfilt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anany\\Desktop\\OSA\\env\\Lib\\site-packages\\scipy\\signal\\_signaltools.py:4525\u001b[39m, in \u001b[36mfiltfilt\u001b[39m\u001b[34m(b, a, x, axis, padtype, padlen, method, irlen)\u001b[39m\n\u001b[32m   4522\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m y\n\u001b[32m   4524\u001b[39m \u001b[38;5;66;03m# method == \"pad\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4525\u001b[39m edge, ext = \u001b[43m_validate_pad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadlen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4526\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mntaps\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4528\u001b[39m \u001b[38;5;66;03m# Get the steady state of the filter's step response.\u001b[39;00m\n\u001b[32m   4529\u001b[39m zi = lfilter_zi(b, a)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anany\\Desktop\\OSA\\env\\Lib\\site-packages\\scipy\\signal\\_signaltools.py:4574\u001b[39m, in \u001b[36m_validate_pad\u001b[39m\u001b[34m(padtype, padlen, x, axis, ntaps)\u001b[39m\n\u001b[32m   4572\u001b[39m \u001b[38;5;66;03m# x's 'axis' dimension must be bigger than edge.\u001b[39;00m\n\u001b[32m   4573\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.shape[axis] <= edge:\n\u001b[32m-> \u001b[39m\u001b[32m4574\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mThe length of the input vector x must be greater \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4575\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[33mthan padlen, which is \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m % edge)\n\u001b[32m   4577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m padtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m edge > \u001b[32m0\u001b[39m:\n\u001b[32m   4578\u001b[39m     \u001b[38;5;66;03m# Make an extension of length `edge` at each\u001b[39;00m\n\u001b[32m   4579\u001b[39m     \u001b[38;5;66;03m# end of the input array.\u001b[39;00m\n\u001b[32m   4580\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m padtype == \u001b[33m'\u001b[39m\u001b[33meven\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[31mValueError\u001b[39m: The length of the input vector x must be greater than padlen, which is 9."
     ]
    }
   ],
   "source": [
    "patient_files = [\n",
    "            # ('C:/Users/anany/Downloads/slp32', 'C:/Users/anany/Downloads/slp32.st'),\n",
    "            # ('C:/Users/anany/Downloads/slp37', 'C:/Users/anany/Downloads/slp37.st'),\n",
    "            # ('C:/Users/anany/Downloads/slp41', 'C:/Users/anany/Downloads/slp41.st'),\n",
    "            ('C:/Users/anany/Downloads/slp45', 'C:/Users/anany/Downloads/slp45.st'),\n",
    "            # ('C:/Users/anany/Downloads/slp48', 'C:/Users/anany/Downloads/slp48.st')\n",
    "        ]\n",
    "\n",
    "combined_signals = []\n",
    "combined_labels = []\n",
    "\n",
    "for dat_file, st_file in patient_files:\n",
    "    record = wfdb.rdrecord(dat_file)  \n",
    "    annotations = wfdb.rdann(dat_file, 'st')  \n",
    "\n",
    "    signals = record.p_signal  \n",
    "    fs = record.fs  \n",
    "    signal_names = record.sig_name  \n",
    "\n",
    "    aux_notes = annotations.aux_note  # Sleep stage and apnea annotations\n",
    "    annotation_times = annotations.sample  # Annotation times (in samples)\n",
    "\n",
    "    stage_mapping = {\n",
    "        'W': 0,  # Wake\n",
    "        '1': 1,  # NREM1\n",
    "        '2': 1,  # NREM2\n",
    "        '3': 1,  # NREM3\n",
    "        '4': 1,  # NREM3 (combined with stage 3)\n",
    "        'R': 1   # REM\n",
    "    }\n",
    "\n",
    "    sleep_stages = []\n",
    "    for aux in aux_notes:\n",
    "        stage = aux.strip()  \n",
    "        if stage in stage_mapping:  # Check if the stage is in the mapping\n",
    "            sleep_stages.append(stage_mapping[stage])\n",
    "\n",
    "    total_samples = len(sleep_stages) * fs * 30  \n",
    "    signals = [signal[:total_samples] for signal in signals.T] \n",
    "    signals = np.array(signals)  \n",
    "\n",
    "    combined_signals.append(signals)\n",
    "    combined_labels.extend(sleep_stages)\n",
    "\n",
    "combined_signals = np.concatenate(combined_signals, axis=1)  \n",
    "combined_labels = np.array(combined_labels)  \n",
    "print(\"Combined signals shape:\", combined_signals.shape)\n",
    "print(\"Combined labels shape:\", combined_labels.shape)\n",
    "print(\"Sampling frequency:\", fs)\n",
    "\n",
    "main_pipeline(combined_signals, combined_labels, fs, \"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined signals shape: (7, 3487500)\n",
      "Combined labels shape: (465,)\n",
      "Sampling frequency: 250\n",
      "Preprocessing signals...\n",
      "Preprocessed signals shape: (7, 3487500)\n",
      "Preprocessing completed.\n",
      "Segmentation started...\n",
      "Segmented signals shape: (465, 52500)\n",
      "Number of labels: 465\n",
      "Feature extraction started...\n",
      "Extracting features...\n",
      "Ensuring consistent feature dimensions...\n",
      "Number of feature dictionaries: 465\n",
      "Feature extraction completed.\n",
      "Normalizing features...\n",
      "Number of normalized feature dictionaries: 465\n",
      "Feature normalization completed.\n",
      "Converting features to matrix...\n",
      "Feature matrix shape: (465, 151)\n",
      "Feature conversion completed.\n",
      "Filtering features based on mutual information...\n",
      "Top 20 Features (Sorted by Importance):\n",
      "D5_percentile_25: 0.1657\n",
      "D5_percentile_75: 0.1618\n",
      "A5_percentile_75: 0.1556\n",
      "A5_percentile_25: 0.1452\n",
      "D4_percentile_75: 0.1212\n",
      "D3_percentile_75: 0.1109\n",
      "D2_percentage_energy: 0.1097\n",
      "D3_percentile_25: 0.1046\n",
      "D1_percentage_energy: 0.0989\n",
      "D1_energy: 0.0954\n",
      "D1_hjorth_activity: 0.0947\n",
      "D1_std: 0.0945\n",
      "D2_ar_coeff_3: 0.0907\n",
      "D3_ar_coeff_4: 0.0837\n",
      "D1_ar_coeff_3: 0.0831\n",
      "D2_range: 0.0704\n",
      "D1_percentile_50: 0.0687\n",
      "D1_percentile_75: 0.0684\n",
      "D4_percentile_25: 0.0676\n",
      "D2_percentile_25: 0.0604\n",
      "\n",
      "Selected Features (MI > 0.01): ['D5_percentile_25', 'D5_percentile_75', 'A5_percentile_75', 'A5_percentile_25', 'D4_percentile_75', 'D3_percentile_75', 'D2_percentage_energy', 'D3_percentile_25', 'D1_percentage_energy', 'D1_energy', 'D1_hjorth_activity', 'D1_std', 'D2_ar_coeff_3', 'D3_ar_coeff_4', 'D1_ar_coeff_3', 'D2_range', 'D1_percentile_50', 'D1_percentile_75', 'D4_percentile_25', 'D2_percentile_25']\n",
      "Feature filtering completed.\n",
      "Performing mRMR feature selection...\n",
      "Mutual Information Scores for All Features:\n",
      "D5_percentile_25: 0.0000\n",
      "D5_percentile_75: 0.0945\n",
      "A5_percentile_75: 0.0954\n",
      "A5_percentile_25: 0.0131\n",
      "D4_percentile_75: 0.0000\n",
      "D3_percentile_75: 0.0989\n",
      "D2_percentage_energy: 0.0000\n",
      "D3_percentile_25: 0.0000\n",
      "D1_percentage_energy: 0.0000\n",
      "D1_energy: 0.0000\n",
      "D1_hjorth_activity: 0.0000\n",
      "D1_std: 0.0000\n",
      "D2_ar_coeff_3: 0.0000\n",
      "D3_ar_coeff_4: 0.0947\n",
      "D1_ar_coeff_3: 0.0490\n",
      "D2_range: 0.0342\n",
      "D1_percentile_50: 0.0000\n",
      "D1_percentile_75: 0.0000\n",
      "D4_percentile_25: 0.0159\n",
      "D2_percentile_25: 0.0592\n",
      "D2_hjorth_mobility: 0.0831\n",
      "D1_ar_coeff_2: 0.0430\n",
      "D5_renyi_entropy: 0.0183\n",
      "D5_tsallis_entropy: 0.0687\n",
      "D2_energy: 0.0684\n",
      "D3_std: 0.0000\n",
      "D3_hjorth_activity: 0.0497\n",
      "D3_energy: 0.0540\n",
      "D2_std: 0.0169\n",
      "D2_hjorth_activity: 0.0704\n",
      "D1_hjorth_mobility: 0.1097\n",
      "D5_shannon_entropy: 0.0000\n",
      "slow_wave_index: 0.0005\n",
      "D5_hjorth_activity: 0.0018\n",
      "D5_std: 0.0000\n",
      "D5_energy: 0.0194\n",
      "D4_percentile_50: 0.0000\n",
      "D4_skewness: 0.0195\n",
      "D1_ar_coeff_4: 0.0491\n",
      "D2_hjorth_complexity: 0.0593\n",
      "D5_range: 0.0430\n",
      "A5_range: 0.0000\n",
      "D2_percentile_75: 0.0000\n",
      "D5_entropy: 0.0000\n",
      "D3_percentage_energy: 0.0320\n",
      "D5_ar_coeff_1: 0.0907\n",
      "D1_hjorth_complexity: 0.0000\n",
      "D2_ar_coeff_2: 0.0604\n",
      "A5_ar_coeff_3: 0.0000\n",
      "A5_spectral_value_at_fc: 0.0386\n",
      "D2_center_frequency: 0.0222\n",
      "D4_hjorth_activity: 0.0511\n",
      "D4_std: 0.0500\n",
      "D4_energy: 0.0266\n",
      "D4_entropy: 0.0000\n",
      "D3_entropy: 0.0353\n",
      "D5_bandwidth: 0.0000\n",
      "D5_ar_coeff_2: 0.0057\n",
      "D3_mean: 0.0055\n",
      "D3_center_frequency: 0.0000\n",
      "D5_hjorth_complexity: 0.0055\n",
      "A5_std: 0.0000\n",
      "D1_percentile_25: 0.0246\n",
      "A5_energy: 0.0505\n",
      "A5_ar_coeff_1: 0.0000\n",
      "D4_percentage_energy: 0.0000\n",
      "A5_hjorth_activity: 0.0000\n",
      "D2_entropy: 0.0000\n",
      "D4_center_frequency: 0.0000\n",
      "D5_ar_coeff_4: 0.0000\n",
      "D1_ar_coeff_1: 0.0040\n",
      "D4_kurtosis: 0.0837\n",
      "D5_percentile_50: 0.1046\n",
      "D5_ar_coeff_3: 0.0000\n",
      "D4_relative: 0.1109\n",
      "A5_mean: 0.0000\n",
      "A5_percentile_50: 0.0296\n",
      "D4_ar_coeff_2: 0.0295\n",
      "D5_spectral_value_at_fc: 0.0287\n",
      "D1_entropy: 0.0099\n",
      "A5_shannon_entropy: 0.0175\n",
      "A5_renyi_entropy: 0.0003\n",
      "A5_ar_coeff_4: 0.0000\n",
      "\n",
      "Top 10 Selected Features: ['D5_percentile_75', 'A5_percentile_75', 'D3_percentile_75', 'D3_ar_coeff_4', 'D2_hjorth_mobility', 'D1_hjorth_mobility', 'D5_ar_coeff_1', 'D4_kurtosis', 'D5_percentile_50', 'D4_relative']\n",
      "mRMR feature selection completed.\n",
      "Top Selected Features: ['D5_percentile_75', 'A5_percentile_75', 'D3_percentile_75', 'D3_ar_coeff_4', 'D2_hjorth_mobility', 'D1_hjorth_mobility', 'D5_ar_coeff_1', 'D4_kurtosis', 'D5_percentile_50', 'D4_relative']\n",
      "Training and evaluating SVM...\n",
      "Training SVM...\n",
      "SVM training completed in 0.01 seconds.\n",
      "Evaluating SVM...\n",
      "Confusion Matrix:\n",
      "[[30  9]\n",
      " [ 6 48]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Wake       0.83      0.77      0.80        39\n",
      "       Sleep       0.84      0.89      0.86        54\n",
      "\n",
      "    accuracy                           0.84        93\n",
      "   macro avg       0.84      0.83      0.83        93\n",
      "weighted avg       0.84      0.84      0.84        93\n",
      "\n",
      "\n",
      "Accuracy: 0.8387096774193549\n",
      "SVM training and evaluation completed.\n",
      "Pipeline completed.\n"
     ]
    }
   ],
   "source": [
    "patient_files = [\n",
    "            # ('C:/Users/anany/Downloads/slp32', 'C:/Users/anany/Downloads/slp32.st'),\n",
    "            # ('C:/Users/anany/Downloads/slp37', 'C:/Users/anany/Downloads/slp37.st'),\n",
    "            # ('C:/Users/anany/Downloads/slp41', 'C:/Users/anany/Downloads/slp41.st'),\n",
    "            # ('C:/Users/anany/Downloads/slp45', 'C:/Users/anany/Downloads/slp45.st'),\n",
    "            ('C:/Users/anany/Downloads/slp48', 'C:/Users/anany/Downloads/slp48.st')\n",
    "        ]\n",
    "\n",
    "combined_signals = []\n",
    "combined_labels = []\n",
    "\n",
    "for dat_file, st_file in patient_files:\n",
    "    record = wfdb.rdrecord(dat_file)  \n",
    "    annotations = wfdb.rdann(dat_file, 'st')  \n",
    "\n",
    "    signals = record.p_signal  \n",
    "    fs = record.fs  \n",
    "    signal_names = record.sig_name  \n",
    "\n",
    "    aux_notes = annotations.aux_note  # Sleep stage and apnea annotations\n",
    "    annotation_times = annotations.sample  # Annotation times (in samples)\n",
    "\n",
    "    stage_mapping = {\n",
    "        'W': 0,  # Wake\n",
    "        '1': 1,  # NREM1\n",
    "        '2': 1,  # NREM2\n",
    "        '3': 1,  # NREM3\n",
    "        '4': 1,  # NREM3 (combined with stage 3)\n",
    "        'R': 1   # REM\n",
    "    }\n",
    "\n",
    "    sleep_stages = []\n",
    "    for aux in aux_notes:\n",
    "        stage = aux.strip()  \n",
    "        if stage in stage_mapping:  # Check if the stage is in the mapping\n",
    "            sleep_stages.append(stage_mapping[stage])\n",
    "\n",
    "    total_samples = len(sleep_stages) * fs * 30  \n",
    "    signals = [signal[:total_samples] for signal in signals.T] \n",
    "    signals = np.array(signals)  \n",
    "\n",
    "    combined_signals.append(signals)\n",
    "    combined_labels.extend(sleep_stages)\n",
    "\n",
    "combined_signals = np.concatenate(combined_signals, axis=1)  \n",
    "combined_labels = np.array(combined_labels)  \n",
    "print(\"Combined signals shape:\", combined_signals.shape)\n",
    "print(\"Combined labels shape:\", combined_labels.shape)\n",
    "print(\"Sampling frequency:\", fs)\n",
    "\n",
    "main_pipeline(combined_signals, combined_labels, fs, \"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined signals shape: (7, 982500)\n",
      "Combined labels shape: (131,)\n",
      "Sampling frequency: 250\n",
      "Preprocessing signals...\n",
      "Preprocessed signals shape: (7, 982500)\n",
      "Preprocessing completed.\n",
      "Segmentation started...\n",
      "Segmented signals shape: (131, 52500)\n",
      "Number of labels: 131\n",
      "Feature extraction started...\n",
      "Extracting features...\n",
      "Ensuring consistent feature dimensions...\n",
      "Number of feature dictionaries: 131\n",
      "Feature extraction completed.\n",
      "Normalizing features...\n",
      "Number of normalized feature dictionaries: 131\n",
      "Feature normalization completed.\n",
      "Converting features to matrix...\n",
      "Feature matrix shape: (131, 151)\n",
      "Feature conversion completed.\n",
      "Filtering features based on mutual information...\n",
      "Top 20 Features (Sorted by Importance):\n",
      "D4_ar_coeff_3: 0.1165\n",
      "D2_energy: 0.1102\n",
      "D5_percentile_50: 0.1096\n",
      "D2_hjorth_activity: 0.1093\n",
      "D2_percentage_energy: 0.1081\n",
      "D2_std: 0.1076\n",
      "A5_percentage_energy: 0.1008\n",
      "A5_percentile_75: 0.0913\n",
      "D2_hjorth_complexity: 0.0899\n",
      "D5_hjorth_complexity: 0.0863\n",
      "D1_ar_coeff_2: 0.0850\n",
      "D1_percentile_75: 0.0831\n",
      "A5_tsallis_entropy: 0.0830\n",
      "D1_percentage_energy: 0.0809\n",
      "A5_renyi_entropy: 0.0806\n",
      "A5_ar_coeff_4: 0.0788\n",
      "D1_hjorth_mobility: 0.0783\n",
      "D5_range: 0.0780\n",
      "A5_ar_coeff_3: 0.0752\n",
      "D4_ar_coeff_4: 0.0735\n",
      "\n",
      "Selected Features (MI > 0.01): ['D4_ar_coeff_3', 'D2_energy', 'D5_percentile_50', 'D2_hjorth_activity', 'D2_percentage_energy', 'D2_std', 'A5_percentage_energy', 'A5_percentile_75', 'D2_hjorth_complexity', 'D5_hjorth_complexity', 'D1_ar_coeff_2', 'D1_percentile_75', 'A5_tsallis_entropy', 'D1_percentage_energy', 'A5_renyi_entropy', 'A5_ar_coeff_4', 'D1_hjorth_mobility', 'D5_range', 'A5_ar_coeff_3', 'D4_ar_coeff_4']\n",
      "Feature filtering completed.\n",
      "Performing mRMR feature selection...\n",
      "Mutual Information Scores for All Features:\n",
      "D4_ar_coeff_3: 0.0000\n",
      "D2_energy: 0.0459\n",
      "D5_percentile_50: 0.0459\n",
      "D2_hjorth_activity: 0.0000\n",
      "D2_percentage_energy: 0.0000\n",
      "D2_std: 0.0809\n",
      "A5_percentage_energy: 0.0000\n",
      "A5_percentile_75: 0.0000\n",
      "D2_hjorth_complexity: 0.0000\n",
      "D5_hjorth_complexity: 0.0082\n",
      "D1_ar_coeff_2: 0.0064\n",
      "D1_percentile_75: 0.0076\n",
      "A5_tsallis_entropy: 0.0458\n",
      "D1_percentage_energy: 0.0459\n",
      "A5_renyi_entropy: 0.0783\n",
      "A5_ar_coeff_4: 0.0420\n",
      "D1_hjorth_mobility: 0.0000\n",
      "D5_range: 0.0188\n",
      "A5_ar_coeff_3: 0.0000\n",
      "D4_ar_coeff_4: 0.0850\n",
      "D4_hjorth_mobility: 0.0699\n",
      "D1_ar_coeff_3: 0.0291\n",
      "D5_center_frequency: 0.0000\n",
      "D4_hjorth_complexity: 0.0000\n",
      "D2_percentile_75: 0.0831\n",
      "D3_hjorth_mobility: 0.0113\n",
      "D3_bandwidth: 0.1076\n",
      "D3_renyi_entropy: 0.1102\n",
      "D3_tsallis_entropy: 0.0000\n",
      "D2_ar_coeff_3: 0.0346\n",
      "D3_ar_coeff_4: 0.1081\n",
      "D5_ar_coeff_2: 0.0191\n",
      "A5_hjorth_complexity: 0.0163\n",
      "D5_kurtosis: 0.0143\n",
      "D4_skewness: 0.0150\n",
      "D2_bandwidth: 0.0120\n",
      "D5_renyi_entropy: 0.0000\n",
      "A5_ar_coeff_1: 0.0000\n",
      "D5_relative: 0.1093\n",
      "D1_std: 0.0000\n",
      "D1_energy: 0.0899\n",
      "D1_hjorth_activity: 0.0000\n",
      "D5_tsallis_entropy: 0.0000\n",
      "D5_hjorth_mobility: 0.0000\n",
      "D4_ar_coeff_1: 0.0000\n",
      "D1_hjorth_complexity: 0.0595\n",
      "A5_shannon_entropy: 0.0297\n",
      "D5_percentile_25: 0.0000\n",
      "D3_skewness: 0.0141\n",
      "D3_spectral_value_at_fc: 0.0640\n",
      "D2_range: 0.0147\n",
      "D4_spectral_value_at_fc: 0.0265\n",
      "D3_relative: 0.0276\n",
      "D5_percentage_energy: 0.0000\n",
      "D4_tsallis_entropy: 0.0000\n",
      "D4_renyi_entropy: 0.0277\n",
      "D4_bandwidth: 0.0000\n",
      "D3_hjorth_complexity: 0.0605\n",
      "D2_ar_coeff_4: 0.0598\n",
      "D1_ar_coeff_4: 0.0751\n",
      "D4_ar_coeff_2: 0.0015\n",
      "D3_percentage_energy: 0.0000\n",
      "D3_energy: 0.0000\n",
      "D3_hjorth_activity: 0.0276\n",
      "A5_spectral_value_at_fc: 0.0635\n",
      "D3_std: 0.0302\n",
      "D4_relative: 0.0362\n",
      "D1_center_frequency: 0.0000\n",
      "D3_ar_coeff_1: 0.0253\n",
      "D3_percentile_50: 0.0000\n",
      "D4_shannon_entropy: 0.0188\n",
      "A5_percentile_25: 0.0584\n",
      "D2_shannon_entropy: 0.0000\n",
      "D3_ar_coeff_3: 0.0229\n",
      "D1_kurtosis: 0.0000\n",
      "A5_relative: 0.0000\n",
      "D5_percentile_75: 0.0000\n",
      "D3_mean: 0.0000\n",
      "D2_renyi_entropy: 0.0052\n",
      "D2_percentile_50: 0.0000\n",
      "D5_mean: 0.0000\n",
      "D2_tsallis_entropy: 0.0209\n",
      "D1_relative: 0.0321\n",
      "D2_mean: 0.0329\n",
      "\n",
      "Top 10 Selected Features: ['D2_std', 'A5_renyi_entropy', 'D4_ar_coeff_4', 'D2_percentile_75', 'D3_bandwidth', 'D3_renyi_entropy', 'D3_ar_coeff_4', 'D5_relative', 'D1_energy', 'D1_ar_coeff_4']\n",
      "mRMR feature selection completed.\n",
      "Top Selected Features: ['D2_std', 'A5_renyi_entropy', 'D4_ar_coeff_4', 'D2_percentile_75', 'D3_bandwidth', 'D3_renyi_entropy', 'D3_ar_coeff_4', 'D5_relative', 'D1_energy', 'D1_ar_coeff_4']\n",
      "Training and evaluating SVM...\n",
      "Training SVM...\n",
      "SVM training completed in 0.00 seconds.\n",
      "Evaluating SVM...\n",
      "Confusion Matrix:\n",
      "[[12  1]\n",
      " [ 6  8]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Wake       0.67      0.92      0.77        13\n",
      "       Sleep       0.89      0.57      0.70        14\n",
      "\n",
      "    accuracy                           0.74        27\n",
      "   macro avg       0.78      0.75      0.73        27\n",
      "weighted avg       0.78      0.74      0.73        27\n",
      "\n",
      "\n",
      "Accuracy: 0.7407407407407407\n",
      "SVM training and evaluation completed.\n",
      "Pipeline completed.\n"
     ]
    }
   ],
   "source": [
    "patient_files = [\n",
    "            ('C:/Users/anany/Downloads/slp37', 'C:/Users/anany/Downloads/slp37.st')\n",
    "        ]\n",
    "\n",
    "combined_signals = []\n",
    "combined_labels = []\n",
    "\n",
    "for dat_file, st_file in patient_files:\n",
    "    record = wfdb.rdrecord(dat_file)  \n",
    "    annotations = wfdb.rdann(dat_file, 'st')  \n",
    "\n",
    "    signals = record.p_signal  \n",
    "    fs = record.fs  \n",
    "    signal_names = record.sig_name  \n",
    "\n",
    "    aux_notes = annotations.aux_note  \n",
    "    annotation_times = annotations.sample  \n",
    "\n",
    "    stage_mapping = {\n",
    "        'W': 0,  # Wake\n",
    "        '1': 1,  # NREM1\n",
    "        '2': 1,  # NREM2\n",
    "        '3': 1,  # NREM3\n",
    "        '4': 1,  # NREM3 (combined with stage 3)\n",
    "        'R': 1   # REM\n",
    "    }\n",
    "\n",
    "    sleep_stages = []\n",
    "    for aux in aux_notes:\n",
    "        stage = aux.strip() \n",
    "        if stage in stage_mapping:  \n",
    "            sleep_stages.append(stage_mapping[stage])\n",
    "\n",
    "    total_samples = len(sleep_stages) * fs * 30  \n",
    "    signals = [signal[:total_samples] for signal in signals.T]  \n",
    "    signals = np.array(signals) \n",
    "\n",
    "    combined_signals.append(signals)\n",
    "    combined_labels.extend(sleep_stages)\n",
    "\n",
    "combined_signals = np.concatenate(combined_signals, axis=1)  \n",
    "combined_labels = np.array(combined_labels) \n",
    "print(\"Combined signals shape:\", combined_signals.shape)\n",
    "print(\"Combined labels shape:\", combined_labels.shape)\n",
    "print(\"Sampling frequency:\", fs)\n",
    "\n",
    "main_pipeline(combined_signals, combined_labels, fs, \"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined signals shape: (7, 3825000)\n",
      "Combined labels shape: (510,)\n",
      "Sampling frequency: 250\n",
      "Preprocessing signals...\n",
      "Preprocessed signals shape: (7, 3825000)\n",
      "Preprocessing completed.\n",
      "Segmentation started...\n",
      "Segmented signals shape: (510, 52500)\n",
      "Number of labels: 510\n",
      "Feature extraction started...\n",
      "Extracting features...\n",
      "Ensuring consistent feature dimensions...\n",
      "Number of feature dictionaries: 510\n",
      "Feature extraction completed.\n",
      "Normalizing features...\n",
      "Number of normalized feature dictionaries: 510\n",
      "Feature normalization completed.\n",
      "Converting features to matrix...\n",
      "Feature matrix shape: (510, 151)\n",
      "Feature conversion completed.\n",
      "Filtering features based on mutual information...\n",
      "Top 20 Features (Sorted by Importance):\n",
      "D2_range: 0.1642\n",
      "A5_percentile_25: 0.1255\n",
      "D4_percentile_75: 0.1236\n",
      "D3_energy: 0.1214\n",
      "D1_range: 0.1158\n",
      "D1_energy: 0.1097\n",
      "D1_hjorth_activity: 0.1090\n",
      "D1_std: 0.1084\n",
      "D3_hjorth_activity: 0.1018\n",
      "D2_std: 0.0978\n",
      "D2_hjorth_activity: 0.0972\n",
      "D3_percentile_75: 0.0970\n",
      "D2_energy: 0.0967\n",
      "D3_percentile_25: 0.0942\n",
      "D4_percentile_25: 0.0874\n",
      "D1_ar_coeff_4: 0.0815\n",
      "D4_hjorth_activity: 0.0806\n",
      "D4_std: 0.0804\n",
      "D4_energy: 0.0797\n",
      "D5_percentile_75: 0.0785\n",
      "\n",
      "Selected Features (MI > 0.01): ['D2_range', 'A5_percentile_25', 'D4_percentile_75', 'D3_energy', 'D1_range', 'D1_energy', 'D1_hjorth_activity', 'D1_std', 'D3_hjorth_activity', 'D2_std', 'D2_hjorth_activity', 'D3_percentile_75', 'D2_energy', 'D3_percentile_25', 'D4_percentile_25', 'D1_ar_coeff_4', 'D4_hjorth_activity', 'D4_std', 'D4_energy', 'D5_percentile_75']\n",
      "Feature filtering completed.\n",
      "Performing mRMR feature selection...\n",
      "Mutual Information Scores for All Features:\n",
      "D2_range: 0.0117\n",
      "A5_percentile_25: 0.1084\n",
      "D4_percentile_75: 0.1097\n",
      "D3_energy: 0.0621\n",
      "D1_range: 0.1158\n",
      "D1_energy: 0.0538\n",
      "D1_hjorth_activity: 0.0572\n",
      "D1_std: 0.0300\n",
      "D3_hjorth_activity: 0.0258\n",
      "D2_std: 0.0138\n",
      "D2_hjorth_activity: 0.0000\n",
      "D3_percentile_75: 0.0152\n",
      "D2_energy: 0.0100\n",
      "D3_percentile_25: 0.1090\n",
      "D4_percentile_25: 0.0063\n",
      "D1_ar_coeff_4: 0.0145\n",
      "D4_hjorth_activity: 0.0004\n",
      "D4_std: 0.0185\n",
      "D4_energy: 0.0057\n",
      "D5_percentile_75: 0.0363\n",
      "D3_std: 0.0540\n",
      "D5_percentile_25: 0.0815\n",
      "A5_percentile_75: 0.0681\n",
      "D3_hjorth_complexity: 0.0017\n",
      "D2_ar_coeff_3: 0.0243\n",
      "D1_percentile_25: 0.0091\n",
      "D3_range: 0.0978\n",
      "D3_percentage_energy: 0.0967\n",
      "D2_ar_coeff_2: 0.0181\n",
      "D2_hjorth_mobility: 0.1642\n",
      "D1_entropy: 0.0354\n",
      "D3_hjorth_mobility: 0.0322\n",
      "D5_range: 0.0228\n",
      "D1_shannon_entropy: 0.0222\n",
      "D2_hjorth_complexity: 0.0000\n",
      "D1_ar_coeff_3: 0.0000\n",
      "D1_percentage_energy: 0.0000\n",
      "D3_ar_coeff_2: 0.0000\n",
      "A5_percentage_energy: 0.0972\n",
      "D4_ar_coeff_3: 0.0638\n",
      "D5_energy: 0.0560\n",
      "D5_std: 0.0214\n",
      "D5_hjorth_complexity: 0.0000\n",
      "D5_hjorth_activity: 0.0000\n",
      "A5_range: 0.0640\n",
      "A5_std: 0.0730\n",
      "A5_hjorth_activity: 0.0146\n",
      "D5_ar_coeff_2: 0.0293\n",
      "A5_energy: 0.0338\n",
      "D1_ar_coeff_2: 0.0148\n",
      "D5_hjorth_mobility: 0.0270\n",
      "D2_percentage_energy: 0.0775\n",
      "D5_percentage_energy: 0.1214\n",
      "D2_percentile_50: 0.0127\n",
      "D5_percentile_50: 0.0656\n",
      "D5_shannon_entropy: 0.0646\n",
      "D2_shannon_entropy: 0.0000\n",
      "D1_tsallis_entropy: 0.0010\n",
      "D2_center_frequency: 0.0000\n",
      "D2_bandwidth: 0.0000\n",
      "D2_percentile_25: 0.0044\n",
      "D5_ar_coeff_4: 0.0154\n",
      "D4_shannon_entropy: 0.0000\n",
      "D4_skewness: 0.1018\n",
      "D3_mean: 0.0588\n",
      "D4_spectral_value_at_fc: 0.0737\n",
      "D1_renyi_entropy: 0.0000\n",
      "A5_ar_coeff_3: 0.0029\n",
      "D1_percentile_75: 0.0053\n",
      "A5_ar_coeff_4: 0.0520\n",
      "D2_spectral_value_at_fc: 0.0112\n",
      "D2_renyi_entropy: 0.0000\n",
      "D2_tsallis_entropy: 0.0942\n",
      "D2_skewness: 0.0211\n",
      "D3_percentile_50: 0.0970\n",
      "D5_entropy: 0.0121\n",
      "D1_kurtosis: 0.0804\n",
      "D2_entropy: 0.0797\n",
      "A5_shannon_entropy: 0.0006\n",
      "D3_relative: 0.0000\n",
      "D2_percentile_75: 0.0000\n",
      "D2_ar_coeff_4: 0.0277\n",
      "D1_hjorth_complexity: 0.0068\n",
      "A5_hjorth_complexity: 0.0073\n",
      "D2_relative: 0.0013\n",
      "A5_spectral_value_at_fc: 0.0000\n",
      "D5_renyi_entropy: 0.0000\n",
      "A5_center_frequency: 0.0000\n",
      "D3_entropy: 0.0806\n",
      "A5_hjorth_mobility: 0.0000\n",
      "D5_tsallis_entropy: 0.0000\n",
      "D4_mean: 0.0274\n",
      "D5_center_frequency: 0.0000\n",
      "D1_mean: 0.0009\n",
      "A5_tsallis_entropy: 0.0000\n",
      "D3_ar_coeff_3: 0.0482\n",
      "D3_bandwidth: 0.0000\n",
      "\n",
      "Top 10 Selected Features: ['A5_percentile_25', 'D4_percentile_75', 'D1_range', 'D3_percentile_25', 'D3_range', 'D2_hjorth_mobility', 'A5_percentage_energy', 'D5_percentage_energy', 'D4_skewness', 'D3_percentile_50']\n",
      "mRMR feature selection completed.\n",
      "Top Selected Features: ['A5_percentile_25', 'D4_percentile_75', 'D1_range', 'D3_percentile_25', 'D3_range', 'D2_hjorth_mobility', 'A5_percentage_energy', 'D5_percentage_energy', 'D4_skewness', 'D3_percentile_50']\n",
      "Training and evaluating SVM...\n",
      "Training SVM...\n",
      "SVM training completed in 0.00 seconds.\n",
      "Evaluating SVM...\n",
      "Confusion Matrix:\n",
      "[[77  0  0  0]\n",
      " [ 3  0  0  0]\n",
      " [12  0  4  0]\n",
      " [ 5  0  1  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Wake       0.79      1.00      0.89        77\n",
      "       NREM1       0.00      0.00      0.00         3\n",
      "       NREM2       0.80      0.25      0.38        16\n",
      "       NREM3       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.79       102\n",
      "   macro avg       0.40      0.31      0.32       102\n",
      "weighted avg       0.72      0.79      0.73       102\n",
      "\n",
      "\n",
      "Accuracy: 0.7941176470588235\n",
      "SVM training and evaluation completed.\n",
      "Pipeline completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anany\\Desktop\\OSA\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anany\\Desktop\\OSA\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anany\\Desktop\\OSA\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "patient_files = [\n",
    "            ('C:/Users/anany/Downloads/slp32', 'C:/Users/anany/Downloads/slp32.st'),\n",
    "            # ('C:/Users/anany/Downloads/slp37', 'C:/Users/anany/Downloads/slp37.st'),\n",
    "            # ('C:/Users/anany/Downloads/slp41', 'C:/Users/anany/Downloads/slp41.st'),\n",
    "            # ('C:/Users/anany/Downloads/slp45', 'C:/Users/anany/Downloads/slp45.st'),\n",
    "            # ('C:/Users/anany/Downloads/slp48', 'C:/Users/anany/Downloads/slp48.st')\n",
    "        ]\n",
    "\n",
    "combined_signals = []\n",
    "combined_labels = []\n",
    "\n",
    "for dat_file, st_file in patient_files:\n",
    "    record = wfdb.rdrecord(dat_file)  \n",
    "    annotations = wfdb.rdann(dat_file, 'st')  \n",
    "\n",
    "    signals = record.p_signal  \n",
    "    fs = record.fs \n",
    "    signal_names = record.sig_name  \n",
    "\n",
    "    aux_notes = annotations.aux_note  \n",
    "    annotation_times = annotations.sample  \n",
    "\n",
    "    stage_mapping = {\n",
    "        'W': 0,  # Wake\n",
    "        '1': 1,  # NREM1\n",
    "        '2': 2,  # NREM2\n",
    "        '3': 3,  # NREM3\n",
    "        '4': 3,  # NREM3 (combined with stage 3)\n",
    "        'R': 4   # REM\n",
    "    }\n",
    "\n",
    "    sleep_stages = []\n",
    "    for aux in aux_notes:\n",
    "        stage = aux.strip()  \n",
    "        if stage in stage_mapping:  \n",
    "            sleep_stages.append(stage_mapping[stage])\n",
    "\n",
    "    total_samples = len(sleep_stages) * fs * 30  \n",
    "    signals = [signal[:total_samples] for signal in signals.T] \n",
    "    signals = np.array(signals) \n",
    "\n",
    "    combined_signals.append(signals)\n",
    "    combined_labels.extend(sleep_stages)\n",
    "\n",
    "combined_signals = np.concatenate(combined_signals, axis=1)  \n",
    "combined_labels = np.array(combined_labels)  \n",
    "\n",
    "print(\"Combined signals shape:\", combined_signals.shape)\n",
    "print(\"Combined labels shape:\", combined_labels.shape)\n",
    "print(\"Sampling frequency:\", fs)\n",
    "\n",
    "main_pipeline(combined_signals, combined_labels, fs, \"multiclass\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined signals shape: (7, 982500)\n",
      "Combined labels shape: (131,)\n",
      "Sampling frequency: 250\n",
      "Preprocessing signals...\n",
      "Preprocessed signals shape: (7, 982500)\n",
      "Preprocessing completed.\n",
      "Segmentation started...\n",
      "Segmented signals shape: (131, 52500)\n",
      "Number of labels: 131\n",
      "Feature extraction started...\n",
      "Extracting features...\n",
      "Ensuring consistent feature dimensions...\n",
      "Number of feature dictionaries: 131\n",
      "Feature extraction completed.\n",
      "Normalizing features...\n",
      "Number of normalized feature dictionaries: 131\n",
      "Feature normalization completed.\n",
      "Converting features to matrix...\n",
      "Feature matrix shape: (131, 151)\n",
      "Feature conversion completed.\n",
      "Filtering features based on mutual information...\n",
      "Top 20 Features (Sorted by Importance):\n",
      "D4_ar_coeff_3: 0.1490\n",
      "D2_hjorth_complexity: 0.1223\n",
      "D1_hjorth_complexity: 0.1040\n",
      "D2_energy: 0.1039\n",
      "D2_hjorth_activity: 0.1028\n",
      "D2_std: 0.1015\n",
      "A5_ar_coeff_3: 0.1006\n",
      "D2_percentage_energy: 0.0977\n",
      "D1_ar_coeff_3: 0.0945\n",
      "D2_ar_coeff_3: 0.0938\n",
      "D5_percentile_50: 0.0934\n",
      "A5_renyi_entropy: 0.0928\n",
      "D3_hjorth_mobility: 0.0925\n",
      "A5_tsallis_entropy: 0.0921\n",
      "D1_percentile_75: 0.0908\n",
      "D1_percentage_energy: 0.0857\n",
      "D4_hjorth_complexity: 0.0843\n",
      "D1_ar_coeff_4: 0.0820\n",
      "D1_hjorth_mobility: 0.0818\n",
      "A5_percentile_75: 0.0796\n",
      "\n",
      "Selected Features (MI > 0.01): ['D4_ar_coeff_3', 'D2_hjorth_complexity', 'D1_hjorth_complexity', 'D2_energy', 'D2_hjorth_activity', 'D2_std', 'A5_ar_coeff_3', 'D2_percentage_energy', 'D1_ar_coeff_3', 'D2_ar_coeff_3', 'D5_percentile_50', 'A5_renyi_entropy', 'D3_hjorth_mobility', 'A5_tsallis_entropy', 'D1_percentile_75', 'D1_percentage_energy', 'D4_hjorth_complexity', 'D1_ar_coeff_4', 'D1_hjorth_mobility', 'A5_percentile_75']\n",
      "Feature filtering completed.\n",
      "Performing mRMR feature selection...\n",
      "Mutual Information Scores for All Features:\n",
      "D4_ar_coeff_3: 0.0000\n",
      "D2_hjorth_complexity: 0.0540\n",
      "D1_hjorth_complexity: 0.0547\n",
      "D2_energy: 0.0000\n",
      "D2_hjorth_activity: 0.0000\n",
      "D2_std: 0.0858\n",
      "A5_ar_coeff_3: 0.0000\n",
      "D2_percentage_energy: 0.0000\n",
      "D1_ar_coeff_3: 0.0000\n",
      "D2_ar_coeff_3: 0.0432\n",
      "D5_percentile_50: 0.0000\n",
      "A5_renyi_entropy: 0.0310\n",
      "D3_hjorth_mobility: 0.0000\n",
      "A5_tsallis_entropy: 0.0546\n",
      "D1_percentile_75: 0.0812\n",
      "D1_percentage_energy: 0.1033\n",
      "D4_hjorth_complexity: 0.0000\n",
      "D1_ar_coeff_4: 0.0021\n",
      "D1_hjorth_mobility: 0.0000\n",
      "A5_percentile_75: 0.0770\n",
      "D3_renyi_entropy: 0.0941\n",
      "D1_ar_coeff_2: 0.0811\n",
      "D3_tsallis_entropy: 0.0000\n",
      "D2_percentile_75: 0.0000\n",
      "A5_shannon_entropy: 0.0911\n",
      "A5_ar_coeff_4: 0.0614\n",
      "D4_ar_coeff_1: 0.1017\n",
      "D2_mean: 0.1039\n",
      "A5_percentage_energy: 0.0000\n",
      "D1_hjorth_activity: 0.0119\n",
      "D1_energy: 0.0977\n",
      "D1_std: 0.0506\n",
      "A5_ar_coeff_1: 0.0436\n",
      "D5_hjorth_mobility: 0.0416\n",
      "D5_hjorth_complexity: 0.0000\n",
      "D2_shannon_entropy: 0.0512\n",
      "D4_ar_coeff_4: 0.0000\n",
      "D5_range: 0.0112\n",
      "D5_renyi_entropy: 0.1032\n",
      "D3_std: 0.0091\n",
      "D3_hjorth_activity: 0.1220\n",
      "D4_spectral_value_at_fc: 0.0000\n",
      "D3_energy: 0.0000\n",
      "D2_renyi_entropy: 0.0000\n",
      "D5_tsallis_entropy: 0.0313\n",
      "D2_tsallis_entropy: 0.0953\n",
      "D4_hjorth_mobility: 0.0184\n",
      "D3_center_frequency: 0.0000\n",
      "D1_relative: 0.0218\n",
      "D3_skewness: 0.0743\n",
      "D5_mean: 0.0145\n",
      "D4_shannon_entropy: 0.0439\n",
      "D3_percentage_energy: 0.0437\n",
      "D2_ar_coeff_2: 0.0000\n",
      "D5_kurtosis: 0.0206\n",
      "D5_ar_coeff_2: 0.0319\n",
      "D4_renyi_entropy: 0.0000\n",
      "D4_tsallis_entropy: 0.0769\n",
      "D2_percentile_50: 0.0754\n",
      "D3_range: 0.0428\n",
      "A5_hjorth_complexity: 0.0000\n",
      "D3_ar_coeff_4: 0.0000\n",
      "A5_percentile_25: 0.0159\n",
      "D2_ar_coeff_4: 0.0436\n",
      "D5_percentile_25: 0.0925\n",
      "D4_ar_coeff_2: 0.0000\n",
      "D3_mean: 0.0361\n",
      "A5_bandwidth: 0.0000\n",
      "D5_relative: 0.0000\n",
      "D2_range: 0.0010\n",
      "D4_center_frequency: 0.0000\n",
      "D4_skewness: 0.0193\n",
      "\n",
      "Top 10 Selected Features: ['D1_percentage_energy', 'D3_renyi_entropy', 'A5_shannon_entropy', 'D4_ar_coeff_1', 'D2_mean', 'D1_energy', 'D5_renyi_entropy', 'D3_hjorth_activity', 'D2_tsallis_entropy', 'D5_percentile_25']\n",
      "mRMR feature selection completed.\n",
      "Top Selected Features: ['D1_percentage_energy', 'D3_renyi_entropy', 'A5_shannon_entropy', 'D4_ar_coeff_1', 'D2_mean', 'D1_energy', 'D5_renyi_entropy', 'D3_hjorth_activity', 'D2_tsallis_entropy', 'D5_percentile_25']\n",
      "Training and evaluating SVM...\n",
      "Training SVM...\n",
      "SVM training completed in 0.00 seconds.\n",
      "Evaluating SVM...\n",
      "Confusion Matrix:\n",
      "[[10  0  3  0]\n",
      " [ 0  0  1  0]\n",
      " [ 5  0  7  0]\n",
      " [ 0  0  1  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Wake       0.67      0.77      0.71        13\n",
      "       NREM1       0.00      0.00      0.00         1\n",
      "       NREM2       0.58      0.58      0.58        12\n",
      "         REM       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.63        27\n",
      "   macro avg       0.31      0.34      0.32        27\n",
      "weighted avg       0.58      0.63      0.60        27\n",
      "\n",
      "\n",
      "Accuracy: 0.6296296296296297\n",
      "SVM training and evaluation completed.\n",
      "Pipeline completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anany\\Desktop\\OSA\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anany\\Desktop\\OSA\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anany\\Desktop\\OSA\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "patient_files = [\n",
    "            # ('C:/Users/anany/Downloads/slp32', 'C:/Users/anany/Downloads/slp32.st'),\n",
    "            ('C:/Users/anany/Downloads/slp37', 'C:/Users/anany/Downloads/slp37.st'),\n",
    "            # ('C:/Users/anany/Downloads/slp41', 'C:/Users/anany/Downloads/slp41.st'),\n",
    "            # ('C:/Users/anany/Downloads/slp45', 'C:/Users/anany/Downloads/slp45.st'),\n",
    "            # ('C:/Users/anany/Downloads/slp48', 'C:/Users/anany/Downloads/slp48.st')\n",
    "        ]\n",
    "\n",
    "combined_signals = []\n",
    "combined_labels = []\n",
    "\n",
    "for dat_file, st_file in patient_files:\n",
    "    record = wfdb.rdrecord(dat_file)  \n",
    "    annotations = wfdb.rdann(dat_file, 'st')  \n",
    "\n",
    "    signals = record.p_signal  \n",
    "    fs = record.fs \n",
    "    signal_names = record.sig_name  \n",
    "\n",
    "    aux_notes = annotations.aux_note  \n",
    "    annotation_times = annotations.sample  \n",
    "\n",
    "    stage_mapping = {\n",
    "        'W': 0,  # Wake\n",
    "        '1': 1,  # NREM1\n",
    "        '2': 2,  # NREM2\n",
    "        '3': 3,  # NREM3\n",
    "        '4': 3,  # NREM3 (combined with stage 3)\n",
    "        'R': 4   # REM\n",
    "    }\n",
    "\n",
    "    sleep_stages = []\n",
    "    for aux in aux_notes:\n",
    "        stage = aux.strip()  \n",
    "        if stage in stage_mapping:  \n",
    "            sleep_stages.append(stage_mapping[stage])\n",
    "\n",
    "    total_samples = len(sleep_stages) * fs * 30  \n",
    "    signals = [signal[:total_samples] for signal in signals.T] \n",
    "    signals = np.array(signals) \n",
    "\n",
    "    combined_signals.append(signals)\n",
    "    combined_labels.extend(sleep_stages)\n",
    "\n",
    "combined_signals = np.concatenate(combined_signals, axis=1)  \n",
    "combined_labels = np.array(combined_labels)  \n",
    "\n",
    "print(\"Combined signals shape:\", combined_signals.shape)\n",
    "print(\"Combined labels shape:\", combined_labels.shape)\n",
    "print(\"Sampling frequency:\", fs)\n",
    "\n",
    "main_pipeline(combined_signals, combined_labels, fs, \"multiclass\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined signals shape: (7, 3487500)\n",
      "Combined labels shape: (465,)\n",
      "Sampling frequency: 250\n",
      "Preprocessing signals...\n",
      "Preprocessed signals shape: (7, 3487500)\n",
      "Preprocessing completed.\n",
      "Segmentation started...\n",
      "Segmented signals shape: (465, 52500)\n",
      "Number of labels: 465\n",
      "Feature extraction started...\n",
      "Extracting features...\n",
      "Ensuring consistent feature dimensions...\n",
      "Number of feature dictionaries: 465\n",
      "Feature extraction completed.\n",
      "Normalizing features...\n",
      "Number of normalized feature dictionaries: 465\n",
      "Feature normalization completed.\n",
      "Converting features to matrix...\n",
      "Feature matrix shape: (465, 151)\n",
      "Feature conversion completed.\n",
      "Filtering features based on mutual information...\n",
      "Top 20 Features (Sorted by Importance):\n",
      "A5_percentile_75: 0.2639\n",
      "A5_percentile_25: 0.2337\n",
      "D5_percentile_75: 0.2334\n",
      "D4_percentile_75: 0.2294\n",
      "D5_percentile_25: 0.2277\n",
      "D2_percentage_energy: 0.1932\n",
      "D1_percentage_energy: 0.1846\n",
      "D3_percentile_25: 0.1790\n",
      "D2_ar_coeff_3: 0.1789\n",
      "D3_ar_coeff_4: 0.1704\n",
      "D4_percentile_25: 0.1683\n",
      "D1_std: 0.1665\n",
      "D1_hjorth_activity: 0.1659\n",
      "D1_energy: 0.1648\n",
      "D1_ar_coeff_3: 0.1486\n",
      "D3_percentile_75: 0.1397\n",
      "D1_ar_coeff_2: 0.1329\n",
      "D1_hjorth_mobility: 0.1245\n",
      "D2_hjorth_mobility: 0.1189\n",
      "D1_percentile_50: 0.1114\n",
      "\n",
      "Selected Features (MI > 0.01): ['A5_percentile_75', 'A5_percentile_25', 'D5_percentile_75', 'D4_percentile_75', 'D5_percentile_25', 'D2_percentage_energy', 'D1_percentage_energy', 'D3_percentile_25', 'D2_ar_coeff_3', 'D3_ar_coeff_4', 'D4_percentile_25', 'D1_std', 'D1_hjorth_activity', 'D1_energy', 'D1_ar_coeff_3', 'D3_percentile_75', 'D1_ar_coeff_2', 'D1_hjorth_mobility', 'D2_hjorth_mobility', 'D1_percentile_50']\n",
      "Feature filtering completed.\n",
      "Performing mRMR feature selection...\n",
      "Mutual Information Scores for All Features:\n",
      "A5_percentile_75: 0.0000\n",
      "A5_percentile_25: 0.1665\n",
      "D5_percentile_75: 0.1648\n",
      "D4_percentile_75: 0.0770\n",
      "D5_percentile_25: 0.0420\n",
      "D2_percentage_energy: 0.1846\n",
      "D1_percentage_energy: 0.0249\n",
      "D3_percentile_25: 0.0091\n",
      "D2_ar_coeff_3: 0.0132\n",
      "D3_ar_coeff_4: 0.1251\n",
      "D4_percentile_25: 0.0000\n",
      "D1_std: 0.0062\n",
      "D1_hjorth_activity: 0.0000\n",
      "D1_energy: 0.1659\n",
      "D1_ar_coeff_3: 0.1245\n",
      "D3_percentile_75: 0.0776\n",
      "D1_ar_coeff_2: 0.0539\n",
      "D1_hjorth_mobility: 0.0555\n",
      "D2_hjorth_mobility: 0.0184\n",
      "D1_percentile_50: 0.1329\n",
      "D1_percentile_75: 0.1486\n",
      "D2_energy: 0.0919\n",
      "D2_std: 0.0852\n",
      "D2_hjorth_activity: 0.1105\n",
      "D1_ar_coeff_4: 0.1092\n",
      "D3_percentage_energy: 0.0336\n",
      "A5_spectral_value_at_fc: 0.1012\n",
      "D1_percentile_25: 0.1033\n",
      "D1_hjorth_complexity: 0.0545\n",
      "D1_entropy: 0.0570\n",
      "D2_percentile_75: 0.1932\n",
      "D5_range: 0.0029\n",
      "D5_entropy: 0.0157\n",
      "D4_kurtosis: 0.0161\n",
      "D2_range: 0.0000\n",
      "D1_kurtosis: 0.0071\n",
      "D2_entropy: 0.0068\n",
      "D1_skewness: 0.0000\n",
      "slow_wave_index: 0.0994\n",
      "D3_std: 0.1189\n",
      "D5_tsallis_entropy: 0.0408\n",
      "D5_renyi_entropy: 0.0099\n",
      "D3_hjorth_activity: 0.0000\n",
      "D3_energy: 0.0376\n",
      "A5_shannon_entropy: 0.0351\n",
      "D4_entropy: 0.1788\n",
      "D5_std: 0.0172\n",
      "D5_hjorth_activity: 0.0296\n",
      "D5_shannon_entropy: 0.0000\n",
      "D5_energy: 0.0716\n",
      "A5_tsallis_entropy: 0.0165\n",
      "D3_renyi_entropy: 0.0536\n",
      "D3_ar_coeff_3: 0.0507\n",
      "D3_bandwidth: 0.0161\n",
      "A5_renyi_entropy: 0.0000\n",
      "D3_tsallis_entropy: 0.0891\n",
      "D1_range: 0.0000\n",
      "A5_range: 0.0432\n",
      "A5_std: 0.0421\n",
      "D2_hjorth_complexity: 0.0089\n",
      "A5_hjorth_activity: 0.0118\n",
      "D4_shannon_entropy: 0.0000\n",
      "A5_energy: 0.0056\n",
      "D2_ar_coeff_1: 0.0510\n",
      "D4_skewness: 0.0353\n",
      "D5_ar_coeff_4: 0.0000\n",
      "D5_hjorth_complexity: 0.0000\n",
      "D3_hjorth_mobility: 0.0000\n",
      "D2_ar_coeff_2: 0.0297\n",
      "D4_ar_coeff_3: 0.0000\n",
      "D2_mean: 0.0426\n",
      "D5_ar_coeff_2: 0.1704\n",
      "A5_ar_coeff_3: 0.1792\n",
      "D4_bandwidth: 0.0080\n",
      "D3_ar_coeff_1: 0.1397\n",
      "D2_percentile_25: 0.0000\n",
      "D1_spectral_value_at_fc: 0.0022\n",
      "D5_kurtosis: 0.0005\n",
      "D4_percentage_energy: 0.0449\n",
      "D5_ar_coeff_1: 0.0196\n",
      "D5_ar_coeff_3: 0.0286\n",
      "D1_shannon_entropy: 0.0397\n",
      "A5_ar_coeff_1: 0.0059\n",
      "D1_relative: 0.0049\n",
      "D5_bandwidth: 0.0387\n",
      "D4_range: 0.0519\n",
      "A5_skewness: 0.0000\n",
      "D1_ar_coeff_1: 0.0000\n",
      "A5_percentage_energy: 0.0021\n",
      "D3_spectral_value_at_fc: 0.0000\n",
      "D2_ar_coeff_4: 0.0000\n",
      "D3_mean: 0.0365\n",
      "D2_renyi_entropy: 0.0571\n",
      "D3_entropy: 0.0000\n",
      "D5_hjorth_mobility: 0.0000\n",
      "A5_percentile_50: 0.0348\n",
      "A5_mean: 0.0038\n",
      "D2_tsallis_entropy: 0.1683\n",
      "A5_kurtosis: 0.0098\n",
      "D5_relative: 0.2291\n",
      "D1_tsallis_entropy: 0.0029\n",
      "D2_center_frequency: 0.0449\n",
      "D1_renyi_entropy: 0.0436\n",
      "D1_bandwidth: 0.0645\n",
      "\n",
      "Top 10 Selected Features: ['A5_percentile_25', 'D5_percentile_75', 'D2_percentage_energy', 'D1_energy', 'D2_percentile_75', 'D4_entropy', 'D5_ar_coeff_2', 'A5_ar_coeff_3', 'D2_tsallis_entropy', 'D5_relative']\n",
      "mRMR feature selection completed.\n",
      "Top Selected Features: ['A5_percentile_25', 'D5_percentile_75', 'D2_percentage_energy', 'D1_energy', 'D2_percentile_75', 'D4_entropy', 'D5_ar_coeff_2', 'A5_ar_coeff_3', 'D2_tsallis_entropy', 'D5_relative']\n",
      "Training and evaluating SVM...\n",
      "Training SVM...\n",
      "SVM training completed in 0.01 seconds.\n",
      "Evaluating SVM...\n",
      "Confusion Matrix:\n",
      "[[35  1  2  0]\n",
      " [ 6  3  8  0]\n",
      " [ 9  9 14  0]\n",
      " [ 0  0  1  5]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Wake       0.70      0.92      0.80        38\n",
      "       NREM1       0.23      0.18      0.20        17\n",
      "       NREM2       0.56      0.44      0.49        32\n",
      "         REM       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.61        93\n",
      "   macro avg       0.62      0.59      0.60        93\n",
      "weighted avg       0.59      0.61      0.59        93\n",
      "\n",
      "\n",
      "Accuracy: 0.6129032258064516\n",
      "SVM training and evaluation completed.\n",
      "Pipeline completed.\n"
     ]
    }
   ],
   "source": [
    "patient_files = [\n",
    "            # ('C:/Users/anany/Downloads/slp32', 'C:/Users/anany/Downloads/slp32.st'),\n",
    "            # ('C:/Users/anany/Downloads/slp37', 'C:/Users/anany/Downloads/slp37.st'),\n",
    "            # ('C:/Users/anany/Downloads/slp41', 'C:/Users/anany/Downloads/slp41.st'),\n",
    "            # ('C:/Users/anany/Downloads/slp45', 'C:/Users/anany/Downloads/slp45.st'),\n",
    "            ('C:/Users/anany/Downloads/slp48', 'C:/Users/anany/Downloads/slp48.st')\n",
    "        ]\n",
    "\n",
    "combined_signals = []\n",
    "combined_labels = []\n",
    "\n",
    "for dat_file, st_file in patient_files:\n",
    "    record = wfdb.rdrecord(dat_file)  \n",
    "    annotations = wfdb.rdann(dat_file, 'st')  \n",
    "\n",
    "    signals = record.p_signal  \n",
    "    fs = record.fs \n",
    "    signal_names = record.sig_name  \n",
    "\n",
    "    aux_notes = annotations.aux_note  \n",
    "    annotation_times = annotations.sample  \n",
    "\n",
    "    stage_mapping = {\n",
    "        'W': 0,  # Wake\n",
    "        '1': 1,  # NREM1\n",
    "        '2': 2,  # NREM2\n",
    "        '3': 3,  # NREM3\n",
    "        '4': 3,  # NREM3 (combined with stage 3)\n",
    "        'R': 4   # REM\n",
    "    }\n",
    "\n",
    "    sleep_stages = []\n",
    "    for aux in aux_notes:\n",
    "        stage = aux.strip()  \n",
    "        if stage in stage_mapping:  \n",
    "            sleep_stages.append(stage_mapping[stage])\n",
    "\n",
    "    total_samples = len(sleep_stages) * fs * 30  \n",
    "    signals = [signal[:total_samples] for signal in signals.T] \n",
    "    signals = np.array(signals) \n",
    "\n",
    "    combined_signals.append(signals)\n",
    "    combined_labels.extend(sleep_stages)\n",
    "\n",
    "combined_signals = np.concatenate(combined_signals, axis=1)  \n",
    "combined_labels = np.array(combined_labels)  \n",
    "\n",
    "print(\"Combined signals shape:\", combined_signals.shape)\n",
    "print(\"Combined labels shape:\", combined_labels.shape)\n",
    "print(\"Sampling frequency:\", fs)\n",
    "\n",
    "main_pipeline(combined_signals, combined_labels, fs, \"multiclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined signals shape: (7, 8295000)\n",
      "Combined labels shape: (1106,)\n",
      "Sampling frequency: 250\n",
      "Preprocessing signals...\n",
      "Preprocessed signals shape: (7, 8295000)\n",
      "Preprocessing completed.\n",
      "Segmentation started...\n",
      "Segmented signals shape: (1106, 52500)\n",
      "Number of labels: 1106\n",
      "Feature extraction started...\n",
      "Extracting features...\n",
      "Ensuring consistent feature dimensions...\n",
      "Number of feature dictionaries: 1106\n",
      "Feature extraction completed.\n",
      "Normalizing features...\n",
      "Number of normalized feature dictionaries: 1106\n",
      "Feature normalization completed.\n",
      "Converting features to matrix...\n",
      "Feature matrix shape: (1106, 151)\n",
      "Feature conversion completed.\n",
      "Filtering features based on mutual information...\n",
      "Top 20 Features (Sorted by Importance):\n",
      "D2_hjorth_mobility: 0.1231\n",
      "D2_ar_coeff_2: 0.1058\n",
      "D1_energy: 0.1042\n",
      "D1_hjorth_activity: 0.1037\n",
      "D1_std: 0.1031\n",
      "D2_energy: 0.1002\n",
      "D1_hjorth_mobility: 0.0984\n",
      "D2_std: 0.0974\n",
      "D2_hjorth_activity: 0.0972\n",
      "D3_hjorth_mobility: 0.0950\n",
      "D1_range: 0.0910\n",
      "D2_hjorth_complexity: 0.0897\n",
      "D2_range: 0.0889\n",
      "D1_percentage_energy: 0.0886\n",
      "D2_ar_coeff_3: 0.0883\n",
      "D3_percentile_25: 0.0855\n",
      "D1_hjorth_complexity: 0.0850\n",
      "D1_ar_coeff_4: 0.0843\n",
      "D2_percentage_energy: 0.0769\n",
      "D3_energy: 0.0751\n",
      "\n",
      "Selected Features (MI > 0.01): ['D2_hjorth_mobility', 'D2_ar_coeff_2', 'D1_energy', 'D1_hjorth_activity', 'D1_std', 'D2_energy', 'D1_hjorth_mobility', 'D2_std', 'D2_hjorth_activity', 'D3_hjorth_mobility', 'D1_range', 'D2_hjorth_complexity', 'D2_range', 'D1_percentage_energy', 'D2_ar_coeff_3', 'D3_percentile_25', 'D1_hjorth_complexity', 'D1_ar_coeff_4', 'D2_percentage_energy', 'D3_energy']\n",
      "Feature filtering completed.\n",
      "Performing mRMR feature selection...\n",
      "Mutual Information Scores for All Features:\n",
      "D2_hjorth_mobility: 0.0015\n",
      "D2_ar_coeff_2: 0.1031\n",
      "D1_energy: 0.1042\n",
      "D1_hjorth_activity: 0.0596\n",
      "D1_std: 0.0910\n",
      "D2_energy: 0.0886\n",
      "D1_hjorth_mobility: 0.0538\n",
      "D2_std: 0.0360\n",
      "D2_hjorth_activity: 0.0389\n",
      "D3_hjorth_mobility: 0.0000\n",
      "D1_range: 0.0000\n",
      "D2_hjorth_complexity: 0.0015\n",
      "D2_range: 0.0164\n",
      "D1_percentage_energy: 0.1037\n",
      "D2_ar_coeff_3: 0.0984\n",
      "D3_percentile_25: 0.0850\n",
      "D1_hjorth_complexity: 0.0231\n",
      "D1_ar_coeff_4: 0.0251\n",
      "D2_percentage_energy: 0.0043\n",
      "D3_energy: 0.0741\n",
      "D4_percentile_75: 0.0580\n",
      "D1_ar_coeff_2: 0.0843\n",
      "D3_percentage_energy: 0.0636\n",
      "D3_hjorth_activity: 0.0101\n",
      "D1_percentile_25: 0.0280\n",
      "D2_shannon_entropy: 0.0304\n",
      "D3_ar_coeff_2: 0.0974\n",
      "D2_ar_coeff_4: 0.1002\n",
      "D5_percentile_75: 0.0000\n",
      "D3_ar_coeff_4: 0.0889\n",
      "D1_entropy: 0.0769\n",
      "D5_percentile_25: 0.0620\n",
      "A5_percentile_75: 0.0435\n",
      "D1_ar_coeff_3: 0.0430\n",
      "A5_percentile_25: 0.0000\n",
      "D3_range: 0.0000\n",
      "D4_entropy: 0.0338\n",
      "A5_range: 0.0081\n",
      "D3_std: 0.0972\n",
      "D1_shannon_entropy: 0.1231\n",
      "D4_std: 0.0897\n",
      "D4_hjorth_activity: 0.0068\n",
      "D4_energy: 0.0168\n",
      "D5_ar_coeff_2: 0.0000\n",
      "D3_percentile_75: 0.1058\n",
      "D2_renyi_entropy: 0.0883\n",
      "D2_tsallis_entropy: 0.0610\n",
      "D5_hjorth_mobility: 0.0000\n",
      "D3_hjorth_complexity: 0.0000\n",
      "D4_percentile_25: 0.0299\n",
      "A5_ar_coeff_3: 0.0099\n",
      "D1_renyi_entropy: 0.0545\n",
      "D4_ar_coeff_3: 0.0751\n",
      "D1_tsallis_entropy: 0.0000\n",
      "D5_range: 0.0559\n",
      "D5_shannon_entropy: 0.0701\n",
      "D3_tsallis_entropy: 0.0000\n",
      "D3_renyi_entropy: 0.0357\n",
      "D5_percentile_50: 0.0358\n",
      "D2_mean: 0.0199\n",
      "D2_spectral_value_at_fc: 0.0000\n",
      "D2_percentile_75: 0.0000\n",
      "D4_bandwidth: 0.0184\n",
      "D5_ar_coeff_4: 0.0656\n",
      "D1_percentile_75: 0.0950\n",
      "A5_shannon_entropy: 0.0421\n",
      "D4_range: 0.0000\n",
      "A5_hjorth_mobility: 0.0087\n",
      "D5_hjorth_complexity: 0.0191\n",
      "D1_kurtosis: 0.0618\n",
      "D4_percentage_energy: 0.0000\n",
      "A5_spectral_value_at_fc: 0.0596\n",
      "D1_skewness: 0.0855\n",
      "A5_entropy: 0.0000\n",
      "D4_percentile_50: 0.0437\n",
      "D5_tsallis_entropy: 0.0000\n",
      "D5_renyi_entropy: 0.0482\n",
      "D3_relative: 0.0466\n",
      "A5_kurtosis: 0.0558\n",
      "D3_ar_coeff_1: 0.0274\n",
      "D4_shannon_entropy: 0.0247\n",
      "D5_kurtosis: 0.0174\n",
      "D4_ar_coeff_4: 0.0057\n",
      "D2_kurtosis: 0.0055\n",
      "A5_percentile_50: 0.0000\n",
      "A5_ar_coeff_4: 0.0000\n",
      "D3_center_frequency: 0.0205\n",
      "D1_relative: 0.0111\n",
      "D1_center_frequency: 0.0478\n",
      "D1_percentile_50: 0.0000\n",
      "\n",
      "Top 10 Selected Features: ['D2_ar_coeff_2', 'D1_energy', 'D1_percentage_energy', 'D2_ar_coeff_3', 'D3_ar_coeff_2', 'D2_ar_coeff_4', 'D3_std', 'D1_shannon_entropy', 'D3_percentile_75', 'D1_percentile_75']\n",
      "mRMR feature selection completed.\n",
      "Top Selected Features: ['D2_ar_coeff_2', 'D1_energy', 'D1_percentage_energy', 'D2_ar_coeff_3', 'D3_ar_coeff_2', 'D2_ar_coeff_4', 'D3_std', 'D1_shannon_entropy', 'D3_percentile_75', 'D1_percentile_75']\n",
      "Training and evaluating SVM...\n",
      "Training SVM...\n",
      "SVM training completed in 0.04 seconds.\n",
      "Evaluating SVM...\n",
      "Confusion Matrix:\n",
      "[[128   0   1   0   0]\n",
      " [ 14   0   6   0   1]\n",
      " [ 43   0  16   0   1]\n",
      " [  4   0   2   0   0]\n",
      " [  2   0   1   0   3]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Wake       0.67      0.99      0.80       129\n",
      "       NREM1       0.00      0.00      0.00        21\n",
      "       NREM2       0.62      0.27      0.37        60\n",
      "       NREM3       0.00      0.00      0.00         6\n",
      "         REM       0.60      0.50      0.55         6\n",
      "\n",
      "    accuracy                           0.66       222\n",
      "   macro avg       0.38      0.35      0.34       222\n",
      "weighted avg       0.57      0.66      0.58       222\n",
      "\n",
      "\n",
      "Accuracy: 0.6621621621621622\n",
      "SVM training and evaluation completed.\n",
      "Pipeline completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anany\\Desktop\\OSA\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anany\\Desktop\\OSA\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anany\\Desktop\\OSA\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "patient_files = [\n",
    "            ('C:/Users/anany/Downloads/slp32', 'C:/Users/anany/Downloads/slp32.st'),\n",
    "            ('C:/Users/anany/Downloads/slp37', 'C:/Users/anany/Downloads/slp37.st'),\n",
    "            ('C:/Users/anany/Downloads/slp41', 'C:/Users/anany/Downloads/slp41.st'),\n",
    "            ('C:/Users/anany/Downloads/slp45', 'C:/Users/anany/Downloads/slp45.st'),\n",
    "            ('C:/Users/anany/Downloads/slp48', 'C:/Users/anany/Downloads/slp48.st')\n",
    "        ]\n",
    "\n",
    "combined_signals = []\n",
    "combined_labels = []\n",
    "\n",
    "\n",
    "\n",
    "for dat_file, st_file in patient_files:\n",
    "    record = wfdb.rdrecord(dat_file)  \n",
    "    annotations = wfdb.rdann(dat_file, 'st')  \n",
    "\n",
    "    signals = record.p_signal  \n",
    "    fs = record.fs \n",
    "    signal_names = record.sig_name  \n",
    "\n",
    "    aux_notes = annotations.aux_note  \n",
    "    annotation_times = annotations.sample  \n",
    "\n",
    "    stage_mapping = {\n",
    "        'W': 0,  # Wake\n",
    "        '1': 1,  # NREM1\n",
    "        '2': 2,  # NREM2\n",
    "        '3': 3,  # NREM3\n",
    "        '4': 3,  # NREM3 (combined with stage 3)\n",
    "        'R': 4   # REM\n",
    "    }\n",
    "\n",
    "    sleep_stages = []\n",
    "    for aux in aux_notes:\n",
    "        stage = aux.strip()  \n",
    "        if stage in stage_mapping:  \n",
    "            sleep_stages.append(stage_mapping[stage])\n",
    "\n",
    "    total_samples = len(sleep_stages) * fs * 30  \n",
    "    signals = [signal[:total_samples] for signal in signals.T] \n",
    "    signals = np.array(signals) \n",
    "\n",
    "    combined_signals.append(signals)\n",
    "    combined_labels.extend(sleep_stages)\n",
    "\n",
    "combined_signals = np.concatenate(combined_signals, axis=1)  \n",
    "combined_labels = np.array(combined_labels)  \n",
    "\n",
    "print(\"Combined signals shape:\", combined_signals.shape)\n",
    "print(\"Combined labels shape:\", combined_labels.shape)\n",
    "print(\"Sampling frequency:\", fs)\n",
    "\n",
    "main_pipeline(combined_signals, combined_labels, fs, \"multiclass\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined signals shape: (7, 3825000)\n",
      "Combined labels shape: (510,)\n",
      "Sampling frequency: 250\n",
      "Preprocessing signals...\n",
      "Preprocessed signals shape: (7, 3825000)\n",
      "Preprocessing completed.\n",
      "Segmentation started...\n",
      "Segmented signals shape: (510, 52500)\n",
      "Number of labels: 510\n",
      "Feature extraction started...\n",
      "Extracting features...\n",
      "Ensuring consistent feature dimensions...\n",
      "Number of feature dictionaries: 510\n",
      "Feature extraction completed.\n",
      "Normalizing features...\n",
      "Number of normalized feature dictionaries: 510\n",
      "Feature normalization completed.\n",
      "Converting features to matrix...\n",
      "Feature matrix shape: (510, 151)\n",
      "Feature conversion completed.\n",
      "Filtering features based on mutual information...\n",
      "Feature filtering completed.\n",
      "Performing mRMR feature selection...\n",
      "mRMR feature selection completed.\n",
      "Training and evaluating SVM...\n",
      "Training SVM...\n",
      "SVM training completed in 0.01 seconds.\n",
      "Evaluating SVM...\n",
      "Confusion Matrix:\n",
      "[[77  0  0  0]\n",
      " [ 3  0  0  0]\n",
      " [12  0  4  0]\n",
      " [ 5  0  1  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Wake       0.79      1.00      0.89        77\n",
      "       NREM1       0.00      0.00      0.00         3\n",
      "       NREM2       0.80      0.25      0.38        16\n",
      "       NREM3       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.79       102\n",
      "   macro avg       0.40      0.31      0.32       102\n",
      "weighted avg       0.72      0.79      0.73       102\n",
      "\n",
      "\n",
      "Accuracy: 0.7941176470588235\n",
      "SVM training and evaluation completed.\n",
      "Pipeline completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anany\\Desktop\\OSA\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anany\\Desktop\\OSA\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anany\\Desktop\\OSA\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "patient_files = [\n",
    "            ('C:/Users/anany/Downloads/slp32', 'C:/Users/anany/Downloads/slp32.st')\n",
    "        ]\n",
    "\n",
    "combined_signals = []\n",
    "combined_labels = []\n",
    "\n",
    "for dat_file, st_file in patient_files:\n",
    "    record = wfdb.rdrecord(dat_file)  \n",
    "    annotations = wfdb.rdann(dat_file, 'st') \n",
    "\n",
    "    signals = record.p_signal  \n",
    "    fs = record.fs  \n",
    "    signal_names = record.sig_name  \n",
    "\n",
    "    aux_notes = annotations.aux_note \n",
    "    annotation_times = annotations.sample  \n",
    "\n",
    "    stage_mapping = {\n",
    "        'W': 0,  # Wake\n",
    "        '1': 1,  # NREM1\n",
    "        '2': 2,  # NREM2\n",
    "        '3': 3,  # NREM3\n",
    "        '4': 3,  # NREM3 (combined with stage 3)\n",
    "        'R': 4   # REM\n",
    "    }\n",
    "\n",
    "    sleep_stages = []\n",
    "    for aux in aux_notes:\n",
    "        stage = aux.strip()  \n",
    "        if stage in stage_mapping:  \n",
    "            sleep_stages.append(stage_mapping[stage])\n",
    "\n",
    "    total_samples = len(sleep_stages) * fs * 30  \n",
    "    signals = [signal[:total_samples] for signal in signals.T]  \n",
    "    signals = np.array(signals)  \n",
    "\n",
    "    combined_signals.append(signals)\n",
    "    combined_labels.extend(sleep_stages)\n",
    "\n",
    "combined_signals = np.concatenate(combined_signals, axis=1)  \n",
    "combined_labels = np.array(combined_labels)  \n",
    "\n",
    "print(\"Combined signals shape:\", combined_signals.shape)\n",
    "print(\"Combined labels shape:\", combined_labels.shape)\n",
    "print(\"Sampling frequency:\", fs)\n",
    "\n",
    "main_pipeline(combined_signals, combined_labels, fs, \"multiclass\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c78e4b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EEG F3-A2', 'EEG F4-A1', 'EEG A1-A2', 'EEG C3-A2', 'EEG C4-A1', 'EEG O1-A2', 'EEG O2-A1', 'EOG LOC-A2', 'EOG ROC-A1', 'EMG Chin', 'Leg 1', 'Leg 2', 'ECG I', 'RR', 'ECG II', 'Snore', 'Flow patient 1', 'Flow patient 2', 'Effort THO', 'Effort ABD', 'SpO2', 'Pleth', 'Body', 'Flow patient 3', 'xPAP CPAP', 'xPAP IPAP', 'xPAP EPAP', 'Leak Total', 'PulseRate', 'PressCheck', 'ECG IIHF', 'Technical']\n"
     ]
    }
   ],
   "source": [
    "from pyedflib import highlevel\n",
    "import pyedflib as plib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics as stat\n",
    "\n",
    "def read_file_signal(file_path, index):\n",
    "    f = plib.EdfReader(file_path)\n",
    "    signal = f.readSignal(index)\n",
    "    f.close()\n",
    "    return signal\n",
    "\n",
    "def signal_labels(file_path):\n",
    "    f = plib.EdfReader(file_path)\n",
    "    labels = f.getSignalLabels()\n",
    "    f.close()\n",
    "    return labels\n",
    "\n",
    "def combined_signal(file_list, index):\n",
    "    combined_signals = []\n",
    "    for file in file_list:\n",
    "        temp = read_file_signal(file, index)\n",
    "        combined_signals.append(temp)\n",
    "    return np.concatenate(combined_signals)\n",
    "\n",
    "def plot_signal(label, signal):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.plot(signal)\n",
    "    plt.title(f\"{label} signal\")\n",
    "    plt.xlabel(\"time\")\n",
    "    plt.ylabel(\"amplitude\")\n",
    "    # plt.ylim(-300, 300)\n",
    "    plt.show()\n",
    "\n",
    "def thresholding(signal, threshold):\n",
    "    mean = signal.mean()\n",
    "    std = np.std(signal)\n",
    "    lower_limit = mean - threshold * std\n",
    "    upper_limit = mean + threshold * std\n",
    "    filtered_signal = np.where((signal >= lower_limit) & (signal <= upper_limit), signal, mean)\n",
    "    return filtered_signal\n",
    "\n",
    "def resample_signal(signal, num_samples):\n",
    "    original_indices = np.linspace(0, len(signal) - 1, num=len(signal))\n",
    "    resampled_indices = np.linspace(0, len(signal) - 1, num=num_samples)\n",
    "    resampled_signal = np.interp(resampled_indices, original_indices, signal)\n",
    "    return resampled_signal\n",
    "\n",
    "def mean_of_interval(signal, start, end):\n",
    "    return stat.mean(signal[start:end])\n",
    "\n",
    "edf_files_severe = [\n",
    "    \"c:\\\\Users\\\\anany\\\\Downloads\\\\00000349-297469[001].edf\",\n",
    "    \"c:\\\\Users\\\\anany\\\\Downloads\\\\00000349-297469[002].edf\",\n",
    "    \"c:\\\\Users\\\\anany\\\\Downloads\\\\00000349-297469[003].edf\",\n",
    "    \"c:\\\\Users\\\\anany\\\\Downloads\\\\00000349-297469[004].edf\",\n",
    "    \"c:\\\\Users\\\\anany\\\\Downloads\\\\00000349-297469[005].edf\",\n",
    "    \"c:\\\\Users\\\\anany\\\\Downloads\\\\00000349-297469[006].edf\",\n",
    "    \"c:\\\\Users\\\\anany\\\\Downloads\\\\00000349-297469[007].edf\",\n",
    "    \"c:\\\\Users\\\\anany\\\\Downloads\\\\00000349-297469[008].edf\",\n",
    "    \"c:\\\\Users\\\\anany\\\\Downloads\\\\00000349-297469[009].edf\",\n",
    "    \"c:\\\\Users\\\\anany\\\\Downloads\\\\00000349-297469[010].edf\"\n",
    "]\n",
    "\n",
    "edf_files_moderate = [\n",
    "    \"C:\\\\Users\\\\anany\\\\Downloads\\\\00000338-297469[001].edf\",\n",
    "    \"C:\\\\Users\\\\anany\\\\Downloads\\\\00000338-297469[002].edf\",\n",
    "    \"C:\\\\Users\\\\anany\\\\Downloads\\\\00000338-297469[003].edf\",\n",
    "    \"C:\\\\Users\\\\anany\\\\Downloads\\\\00000338-297469[004].edf\",\n",
    "    \"C:\\\\Users\\\\anany\\\\Downloads\\\\00000338-297469[005].edf\",\n",
    "    \"C:\\\\Users\\\\anany\\\\Downloads\\\\00000338-297469[006].edf\",\n",
    "    \"C:\\\\Users\\\\anany\\\\Downloads\\\\00000338-297469[007].edf\",\n",
    "    \"C:\\\\Users\\\\anany\\\\Downloads\\\\00000338-297469[008].edf\",\n",
    "    \"C:\\\\Users\\\\anany\\\\Downloads\\\\00000338-297469[009].edf\",\n",
    "    \"C:\\\\Users\\\\anany\\\\Downloads\\\\00000338-297469[010].edf\",\n",
    "    \"C:\\\\Users\\\\anany\\\\Downloads\\\\00000338-297469[011].edf\"\n",
    "]\n",
    "\n",
    "edf_files_mild = [\n",
    "    \"C:\\\\Users\\\\anany\\\\Downloads\\\\00000336-297469[001].edf\",\n",
    "    \"C:\\\\Users\\\\anany\\\\Downloads\\\\00000336-297469[002].edf\",\n",
    "    \"C:\\\\Users\\\\anany\\\\Downloads\\\\00000336-297469[003].edf\",\n",
    "    \"C:\\\\Users\\\\anany\\\\Downloads\\\\00000336-297469[004].edf\",\n",
    "    \"C:\\\\Users\\\\anany\\\\Downloads\\\\00000336-297469[005].edf\",\n",
    "    \"C:\\\\Users\\\\anany\\\\Downloads\\\\00000336-297469[006].edf\",\n",
    "    \"C:\\\\Users\\\\anany\\\\Downloads\\\\00000336-297469[007].edf\",\n",
    "    \"C:\\\\Users\\\\anany\\\\Downloads\\\\00000336-297469[008].edf\",\n",
    "    \"C:\\\\Users\\\\anany\\\\Downloads\\\\00000336-297469[009].edf\",\n",
    "    \"C:\\\\Users\\\\anany\\\\Downloads\\\\00000336-297469[010].edf\",\n",
    "    \"C:\\\\Users\\\\anany\\\\Downloads\\\\00000336-297469[011].edf\"\n",
    "]\n",
    "\n",
    "labels = signal_labels(edf_files_severe[0])\n",
    "labels[16] = \"Flow patient 1\"\n",
    "labels[17] = \"Flow patient 2\"\n",
    "labels[23] = \"Flow patient 3\"\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac939929",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_indices = [0, 1, 2, 4, 5, 6, 7, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8c0ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720000 720000\n"
     ]
    }
   ],
   "source": [
    "signal_11 = read_file_signal(edf_files_severe[0], 8)\n",
    "signal_12 = read_file_signal(edf_files_severe[0], 9)\n",
    "print(len(signal_11), len(signal_12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65d0c735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720000 720000\n"
     ]
    }
   ],
   "source": [
    "signal_21 = read_file_signal(edf_files_moderate[0], 9)\n",
    "signal_22 = read_file_signal(edf_files_moderate[0], 10)\n",
    "print(len(signal_21), len(signal_22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b75dcbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720000 720000\n"
     ]
    }
   ],
   "source": [
    "signal_31 = read_file_signal(edf_files_mild[0], 9)\n",
    "signal_32 = read_file_signal(edf_files_mild[0], 10)\n",
    "print(len(signal_31), len(signal_32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d31f101e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rates: {0: 200.0, 1: 200.0, 2: 200.0, 4: 200.0, 5: 200.0, 6: 200.0, 7: 200.0, 8: 200.0, 9: 200.0}\n",
      "Signal shape for channel 0: (6922200,)\n"
     ]
    }
   ],
   "source": [
    "channels_of_interest = [0, 1, 2, 4, 5, 6, 7, 8, 9]\n",
    "channel_data = {ch: [] for ch in channels_of_interest}\n",
    "sample_rates = {}\n",
    "\n",
    "# First, check and store sample rates\n",
    "edf = plib.EdfReader(edf_files_severe[0])\n",
    "for ch in channels_of_interest:\n",
    "    sample_rates[ch] = edf.getSampleFrequency(ch)\n",
    "edf.close()\n",
    "\n",
    "# Read and concatenate each channel across files\n",
    "for file in edf_files_severe:\n",
    "    f = plib.EdfReader(file)\n",
    "    for ch in channels_of_interest:\n",
    "        signal = f.readSignal(ch)\n",
    "        channel_data[ch].append(signal)\n",
    "    f.close()\n",
    "\n",
    "# Concatenate all signals\n",
    "for ch in channels_of_interest:\n",
    "    channel_data[ch] = np.concatenate(channel_data[ch])\n",
    "\n",
    "# Done! You now have:\n",
    "# - `channel_data[ch]` as full 10-hour signal for channel `ch`\n",
    "# - `sample_rates[ch]` as sample rate of each channel\n",
    "\n",
    "print(\"Sample rates:\", sample_rates)\n",
    "print(\"Signal shape for channel 0:\", channel_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cc003e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing signals...\n",
      "Preprocessed signals shape: (9, 6918000)\n",
      "Preprocessing completed.\n",
      "Segmentation started...\n",
      "Segmented signals shape: (1153, 54000)\n",
      "Number of labels: 1153\n",
      "Feature extraction started...\n",
      "Extracting features...\n",
      "Ensuring consistent feature dimensions...\n",
      "Number of feature dictionaries: 1153\n",
      "Feature extraction completed.\n",
      "Normalizing features...\n",
      "Number of normalized feature dictionaries: 1153\n",
      "Feature normalization completed.\n",
      "Converting features to matrix...\n",
      "Feature matrix shape: (1153, 151)\n",
      "Feature conversion completed.\n",
      "Filtering features based on mutual information...\n",
      "Feature filtering completed.\n",
      "Performing mRMR feature selection...\n",
      "mRMR feature selection completed.\n",
      "Training and evaluating SVM...\n",
      "Training SVM...\n",
      "SVM training completed in 0.00 seconds.\n",
      "Evaluating SVM...\n",
      "Confusion Matrix:\n",
      "[[  2   9]\n",
      " [  0 220]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Wake       1.00      0.18      0.31        11\n",
      "       Sleep       0.96      1.00      0.98       220\n",
      "\n",
      "    accuracy                           0.96       231\n",
      "   macro avg       0.98      0.59      0.64       231\n",
      "weighted avg       0.96      0.96      0.95       231\n",
      "\n",
      "\n",
      "Accuracy: 0.961038961038961\n",
      "SVM training and evaluation completed.\n",
      "Pipeline completed.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import pyedflib\n",
    "from utils import main_pipeline  # Assuming you have a main_pipeline function defined in utils.py\n",
    "\n",
    "def read_edf_signals(edf_paths, selected_indices):\n",
    "    combined_signals = []\n",
    "\n",
    "    for edf_path in edf_paths:\n",
    "        f = pyedflib.EdfReader(edf_path)\n",
    "        n = f.signals_in_file\n",
    "        fs = int(f.getSampleFrequency(0))  # assuming all selected have same fs\n",
    "\n",
    "        # Read and stack selected channels\n",
    "        signals = []\n",
    "        for i in selected_indices:\n",
    "            signal = f.readSignal(i)\n",
    "            signals.append(signal)\n",
    "        f._close()\n",
    "        del f\n",
    "\n",
    "        signals = np.array(signals)\n",
    "        combined_signals.append(signals)\n",
    "\n",
    "    # Concatenate along time axis (i.e. axis=1)\n",
    "    combined_signals = np.concatenate(combined_signals, axis=1)\n",
    "    return combined_signals, fs\n",
    "\n",
    "\n",
    "def parse_rml_to_labels_binary(rml_path, total_duration_secs):\n",
    "    tree = ET.parse(rml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    stages = []\n",
    "    for stage in root.findall(\".//User/Stage\"):\n",
    "        stage_type = stage.get(\"Type\")\n",
    "        start_time = int(stage.get(\"Start\"))\n",
    "        stages.append((stage_type, start_time))\n",
    "\n",
    "    stages.sort(key=lambda x: x[1])\n",
    "\n",
    "    # Binary mapping: Wake=0, all else=1\n",
    "    stage_mapping = {\n",
    "        'Wake': 0,\n",
    "        'NonREM1': 1,\n",
    "        'NonREM2': 1,\n",
    "        'NonREM3': 1,\n",
    "        'REM': 1\n",
    "    }\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    for i in range(len(stages)):\n",
    "        label = stage_mapping[stages[i][0]]\n",
    "        start = stages[i][1]\n",
    "        end = stages[i+1][1] if i + 1 < len(stages) else total_duration_secs\n",
    "        duration = end - start\n",
    "        num_epochs = duration // 30\n",
    "        labels.extend([label] * num_epochs)\n",
    "\n",
    "    return np.array(labels)\n",
    "\n",
    "def parse_rml_to_labels_multi(rml_path, total_duration_secs):\n",
    "    tree = ET.parse(rml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    stages = []\n",
    "    for stage in root.findall(\".//User/Stage\"):\n",
    "        stage_type = stage.get(\"Type\")\n",
    "        start_time = int(stage.get(\"Start\"))\n",
    "        stages.append((stage_type, start_time))\n",
    "\n",
    "    stages.sort(key=lambda x: x[1])\n",
    "\n",
    "    # Binary mapping: Wake=0, all else=1\n",
    "    stage_mapping = {\n",
    "        'Wake': 0,\n",
    "        'NonREM1': 1,\n",
    "        'NonREM2': 2,\n",
    "        'NonREM3': 3,\n",
    "        'REM': 4\n",
    "    }\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    for i in range(len(stages)):\n",
    "        label = stage_mapping[stages[i][0]]\n",
    "        start = stages[i][1]\n",
    "        end = stages[i+1][1] if i + 1 < len(stages) else total_duration_secs\n",
    "        duration = end - start\n",
    "        num_epochs = duration // 30\n",
    "        labels.extend([label] * num_epochs)\n",
    "\n",
    "    return np.array(labels)\n",
    "\n",
    "\n",
    "# Indices of channels you want to keep: 0,1,2,4,5,6,7,8,9\n",
    "\n",
    "# Read and combine signal data\n",
    "combined_signals, fs = read_edf_signals(edf_files_severe, selected_indices)\n",
    "\n",
    "# Get total duration (in seconds)\n",
    "total_duration_secs = combined_signals.shape[1] // fs\n",
    "\n",
    "# Path to your RML file\n",
    "rml_file_path = \"C:\\\\Users\\\\anany\\\\Desktop\\\\OSA\\\\user_severe_349.rml\"\n",
    "\n",
    "# Parse RML to get binary labels\n",
    "combined_labels = parse_rml_to_labels_binary(rml_file_path, total_duration_secs)\n",
    "\n",
    "# Optional: Trim signals to match number of epochs\n",
    "required_samples = len(combined_labels) * 30 * fs\n",
    "combined_signals = combined_signals[:, :required_samples]\n",
    "\n",
    "# Call your pipeline\n",
    "main_pipeline(combined_signals, combined_labels, fs, \"binary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d061349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing signals...\n",
      "Preprocessed signals shape: (9, 6918000)\n",
      "Preprocessing completed.\n",
      "Segmentation started...\n",
      "Segmented signals shape: (1153, 54000)\n",
      "Number of labels: 1153\n",
      "Feature extraction started...\n",
      "Extracting features...\n",
      "Ensuring consistent feature dimensions...\n",
      "Number of feature dictionaries: 1153\n",
      "Feature extraction completed.\n",
      "Normalizing features...\n",
      "Number of normalized feature dictionaries: 1153\n",
      "Feature normalization completed.\n",
      "Converting features to matrix...\n",
      "Feature matrix shape: (1153, 151)\n",
      "Feature conversion completed.\n",
      "Filtering features based on mutual information...\n",
      "Feature filtering completed.\n",
      "Performing mRMR feature selection...\n",
      "mRMR feature selection completed.\n",
      "Training and evaluating SVM...\n",
      "Training SVM...\n",
      "SVM training completed in 0.02 seconds.\n",
      "Evaluating SVM...\n",
      "Confusion Matrix:\n",
      "[[ 3  0  1  4  3]\n",
      " [ 0  0  6  0 10]\n",
      " [ 0  0  8 30 18]\n",
      " [ 0  0  5 69  5]\n",
      " [ 0  0  5 14 50]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Wake       1.00      0.27      0.43        11\n",
      "       NREM1       0.00      0.00      0.00        16\n",
      "       NREM2       0.32      0.14      0.20        56\n",
      "       NREM3       0.59      0.87      0.70        79\n",
      "         REM       0.58      0.72      0.65        69\n",
      "\n",
      "    accuracy                           0.56       231\n",
      "   macro avg       0.50      0.40      0.40       231\n",
      "weighted avg       0.50      0.56      0.50       231\n",
      "\n",
      "\n",
      "Accuracy: 0.5627705627705628\n",
      "SVM training and evaluation completed.\n",
      "Pipeline completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anany\\Desktop\\OSA\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anany\\Desktop\\OSA\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anany\\Desktop\\OSA\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "combined_signals, fs = read_edf_signals(edf_files_severe, selected_indices)\n",
    "\n",
    "# Get total duration (in seconds)\n",
    "total_duration_secs = combined_signals.shape[1] // fs\n",
    "\n",
    "# Path to your RML file\n",
    "rml_file_path = \"C:\\\\Users\\\\anany\\\\Desktop\\\\OSA\\\\user_severe_349.rml\"\n",
    "\n",
    "# Parse RML to get binary labels\n",
    "combined_labels = parse_rml_to_labels_multi(rml_file_path, total_duration_secs)\n",
    "\n",
    "# Optional: Trim signals to match number of epochs\n",
    "required_samples = len(combined_labels) * 30 * fs\n",
    "combined_signals = combined_signals[:, :required_samples]\n",
    "\n",
    "# Call your pipeline\n",
    "main_pipeline(combined_signals, combined_labels, fs, \"multiclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfc9d23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing signals...\n",
      "Preprocessed signals shape: (9, 7230000)\n",
      "Preprocessing completed.\n",
      "Segmentation started...\n",
      "Segmented signals shape: (1205, 54000)\n",
      "Number of labels: 1205\n",
      "Feature extraction started...\n",
      "Extracting features...\n",
      "Ensuring consistent feature dimensions...\n",
      "Number of feature dictionaries: 1205\n",
      "Feature extraction completed.\n",
      "Normalizing features...\n",
      "Number of normalized feature dictionaries: 1205\n",
      "Feature normalization completed.\n",
      "Converting features to matrix...\n",
      "Feature matrix shape: (1205, 151)\n",
      "Feature conversion completed.\n",
      "Filtering features based on mutual information...\n",
      "Feature filtering completed.\n",
      "Performing mRMR feature selection...\n",
      "mRMR feature selection completed.\n",
      "Training and evaluating SVM...\n",
      "Training SVM...\n",
      "SVM training completed in 0.01 seconds.\n",
      "Evaluating SVM...\n",
      "Confusion Matrix:\n",
      "[[ 40  17]\n",
      " [  3 181]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Wake       0.93      0.70      0.80        57\n",
      "       Sleep       0.91      0.98      0.95       184\n",
      "\n",
      "    accuracy                           0.92       241\n",
      "   macro avg       0.92      0.84      0.87       241\n",
      "weighted avg       0.92      0.92      0.91       241\n",
      "\n",
      "\n",
      "Accuracy: 0.91701244813278\n",
      "SVM training and evaluation completed.\n",
      "Pipeline completed.\n"
     ]
    }
   ],
   "source": [
    "combined_signals, fs = read_edf_signals(edf_files_moderate, selected_indices)\n",
    "\n",
    "# Get total duration (in seconds)\n",
    "total_duration_secs = combined_signals.shape[1] // fs\n",
    "\n",
    "# Path to your RML file\n",
    "rml_file_path = \"C:\\\\Users\\\\anany\\\\Desktop\\\\OSA\\\\moderate_338.rml\"\n",
    "\n",
    "# Parse RML to get binary labels\n",
    "combined_labels = parse_rml_to_labels_binary(rml_file_path, total_duration_secs)\n",
    "\n",
    "# Optional: Trim signals to match number of epochs\n",
    "required_samples = len(combined_labels) * 30 * fs\n",
    "combined_signals = combined_signals[:, :required_samples]\n",
    "\n",
    "# Call your pipeline\n",
    "main_pipeline(combined_signals, combined_labels, fs, \"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cacc38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing signals...\n",
      "Preprocessed signals shape: (9, 7230000)\n",
      "Preprocessing completed.\n",
      "Segmentation started...\n",
      "Segmented signals shape: (1205, 54000)\n",
      "Number of labels: 1205\n",
      "Feature extraction started...\n",
      "Extracting features...\n",
      "Ensuring consistent feature dimensions...\n",
      "Number of feature dictionaries: 1205\n",
      "Feature extraction completed.\n",
      "Normalizing features...\n",
      "Number of normalized feature dictionaries: 1205\n",
      "Feature normalization completed.\n",
      "Converting features to matrix...\n",
      "Feature matrix shape: (1205, 151)\n",
      "Feature conversion completed.\n",
      "Filtering features based on mutual information...\n",
      "Feature filtering completed.\n",
      "Performing mRMR feature selection...\n",
      "mRMR feature selection completed.\n",
      "Training and evaluating SVM...\n",
      "Training SVM...\n",
      "SVM training completed in 0.02 seconds.\n",
      "Evaluating SVM...\n",
      "Confusion Matrix:\n",
      "[[44 11  1  1  0]\n",
      " [ 6 42 17  1  0]\n",
      " [ 1 25 18  8  0]\n",
      " [ 0  3  5 27  0]\n",
      " [ 0 29  2  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Wake       0.86      0.77      0.81        57\n",
      "       NREM1       0.38      0.64      0.48        66\n",
      "       NREM2       0.42      0.35      0.38        52\n",
      "       NREM3       0.73      0.77      0.75        35\n",
      "         REM       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.54       241\n",
      "   macro avg       0.48      0.51      0.48       241\n",
      "weighted avg       0.50      0.54      0.51       241\n",
      "\n",
      "\n",
      "Accuracy: 0.5435684647302904\n",
      "SVM training and evaluation completed.\n",
      "Pipeline completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anany\\Desktop\\OSA\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anany\\Desktop\\OSA\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anany\\Desktop\\OSA\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "combined_signals, fs = read_edf_signals(edf_files_moderate, selected_indices)\n",
    "\n",
    "# Get total duration (in seconds)\n",
    "total_duration_secs = combined_signals.shape[1] // fs\n",
    "\n",
    "# Path to your RML file\n",
    "rml_file_path = \"C:\\\\Users\\\\anany\\\\Desktop\\\\OSA\\\\moderate_338.rml\"\n",
    "\n",
    "# Parse RML to get multi labels\n",
    "combined_labels = parse_rml_to_labels_multi(rml_file_path, total_duration_secs)\n",
    "\n",
    "# Optional: Trim signals to match number of epochs\n",
    "required_samples = len(combined_labels) * 30 * fs\n",
    "combined_signals = combined_signals[:, :required_samples]\n",
    "\n",
    "# Call your pipeline\n",
    "main_pipeline(combined_signals, combined_labels, fs, \"multiclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f2a0f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing signals...\n",
      "Preprocessed signals shape: (9, 7458000)\n",
      "Preprocessing completed.\n",
      "Segmentation started...\n",
      "Segmented signals shape: (1243, 54000)\n",
      "Number of labels: 1243\n",
      "Feature extraction started...\n",
      "Extracting features...\n",
      "Ensuring consistent feature dimensions...\n",
      "Number of feature dictionaries: 1243\n",
      "Feature extraction completed.\n",
      "Normalizing features...\n",
      "Number of normalized feature dictionaries: 1243\n",
      "Feature normalization completed.\n",
      "Converting features to matrix...\n",
      "Feature matrix shape: (1243, 151)\n",
      "Feature conversion completed.\n",
      "Filtering features based on mutual information...\n",
      "Feature filtering completed.\n",
      "Performing mRMR feature selection...\n",
      "mRMR feature selection completed.\n",
      "Training and evaluating SVM...\n",
      "Training SVM...\n",
      "SVM training completed in 0.01 seconds.\n",
      "Evaluating SVM...\n",
      "Confusion Matrix:\n",
      "[[ 31  38]\n",
      " [  3 177]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Wake       0.91      0.45      0.60        69\n",
      "       Sleep       0.82      0.98      0.90       180\n",
      "\n",
      "    accuracy                           0.84       249\n",
      "   macro avg       0.87      0.72      0.75       249\n",
      "weighted avg       0.85      0.84      0.81       249\n",
      "\n",
      "\n",
      "Accuracy: 0.8353413654618473\n",
      "SVM training and evaluation completed.\n",
      "Pipeline completed.\n"
     ]
    }
   ],
   "source": [
    "combined_signals, fs = read_edf_signals(edf_files_mild, selected_indices)\n",
    "\n",
    "# Get total duration (in seconds)\n",
    "total_duration_secs = combined_signals.shape[1] // fs\n",
    "\n",
    "# Path to your RML file\n",
    "rml_file_path = \"C:\\\\Users\\\\anany\\\\Desktop\\\\OSA\\\\user_mild_336.rml\"\n",
    "\n",
    "# Parse RML to get binary labels\n",
    "combined_labels = parse_rml_to_labels_binary(rml_file_path, total_duration_secs)\n",
    "\n",
    "# Optional: Trim signals to match number of epochs\n",
    "required_samples = len(combined_labels) * 30 * fs\n",
    "combined_signals = combined_signals[:, :required_samples]\n",
    "\n",
    "# Call your pipeline\n",
    "main_pipeline(combined_signals, combined_labels, fs, \"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c1721b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing signals...\n",
      "Preprocessed signals shape: (9, 7458000)\n",
      "Preprocessing completed.\n",
      "Segmentation started...\n",
      "Segmented signals shape: (1243, 54000)\n",
      "Number of labels: 1243\n",
      "Feature extraction started...\n",
      "Extracting features...\n",
      "Ensuring consistent feature dimensions...\n",
      "Number of feature dictionaries: 1243\n",
      "Feature extraction completed.\n",
      "Normalizing features...\n",
      "Number of normalized feature dictionaries: 1243\n",
      "Feature normalization completed.\n",
      "Converting features to matrix...\n",
      "Feature matrix shape: (1243, 151)\n",
      "Feature conversion completed.\n",
      "Filtering features based on mutual information...\n",
      "Feature filtering completed.\n",
      "Performing mRMR feature selection...\n",
      "mRMR feature selection completed.\n",
      "Training and evaluating SVM...\n",
      "Training SVM...\n",
      "SVM training completed in 0.02 seconds.\n",
      "Evaluating SVM...\n",
      "Confusion Matrix:\n",
      "[[49 15  5  0  0]\n",
      " [ 3 26 13  0  0]\n",
      " [ 1 17 40  8  0]\n",
      " [ 1  1 25 15  0]\n",
      " [ 4 25  1  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Wake       0.84      0.71      0.77        69\n",
      "       NREM1       0.31      0.62      0.41        42\n",
      "       NREM2       0.48      0.61      0.53        66\n",
      "       NREM3       0.65      0.36      0.46        42\n",
      "         REM       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.52       249\n",
      "   macro avg       0.46      0.46      0.44       249\n",
      "weighted avg       0.52      0.52      0.50       249\n",
      "\n",
      "\n",
      "Accuracy: 0.5220883534136547\n",
      "SVM training and evaluation completed.\n",
      "Pipeline completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anany\\Desktop\\OSA\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anany\\Desktop\\OSA\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anany\\Desktop\\OSA\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "combined_signals, fs = read_edf_signals(edf_files_mild, selected_indices)\n",
    "\n",
    "# Get total duration (in seconds)\n",
    "total_duration_secs = combined_signals.shape[1] // fs\n",
    "\n",
    "# Path to your RML file\n",
    "rml_file_path = \"C:\\\\Users\\\\anany\\\\Desktop\\\\OSA\\\\user_mild_336.rml\"\n",
    "\n",
    "# Parse RML to get multi labels\n",
    "combined_labels = parse_rml_to_labels_multi(rml_file_path, total_duration_secs)\n",
    "\n",
    "# Optional: Trim signals to match number of epochs\n",
    "required_samples = len(combined_labels) * 30 * fs\n",
    "combined_signals = combined_signals[:, :required_samples]\n",
    "\n",
    "# Call your pipeline\n",
    "main_pipeline(combined_signals, combined_labels, fs, \"multiclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fa801f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
